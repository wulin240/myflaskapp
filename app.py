from flask import Flask, render_template, request, jsonify
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import urllib.parse
from datetime import datetime, timedelta
import json # ç¢ºä¿å¯ä»¥è™•ç† JSON éŸ¿æ‡‰

app = Flask(__name__)

# ----------------- Supabase è¨­å®š -----------------
# è«‹å°‡é€™è£¡æ›¿æ›æˆæ‚¨çš„ Supabase å°ˆæ¡ˆè³‡è¨Š
SUPABASE_URL = "https://djhdpltrhlhqfxmwniki.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImRqaGRwbHRyaGxocWZ4bXduaWtpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjMwNjQwODgsImV4cCI6MjA3ODY0MDA4OH0.jwSPe-HMHxv2xGCjS42O5Cjby0KtgsHEStlQWs0cyPk"
TABLE_NAME = "stock_data"
FAVORITE_TABLE = "favorites"

headers = {
    "apikey": SUPABASE_KEY.strip(),
    "Authorization": f"Bearer {SUPABASE_KEY.strip()}",
    "Content-Type": "application/json" # æ–°å¢ Content-Type ç¢ºä¿ POST/DELETE æ­£ç¢º
}

# ----------------- è¼”åŠ©å‡½æ•¸ï¼šæœ€æ„›è‚¡ç¥¨æª¢æŸ¥ -----------------
def is_favorite(stock_id):
    """æª¢æŸ¥è‚¡ç¥¨æ˜¯å¦å·²åŠ å…¥æœ€æ„›"""
    try:
        # ä½¿ç”¨ count æŸ¥è©¢ä¾†å„ªåŒ–æ€§èƒ½
        params = {"stock_id": f"eq.{stock_id}", "select": "count"}
        res = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params=params, timeout=10)
        res.raise_for_status()
        # Supabase count å›æ‡‰æœƒåœ¨ Headers ä¸­çš„ Content-Range
        return int(res.headers.get("Content-Range").split('/')[-1]) > 0
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥æœ€æ„›å¤±æ•—: {e}")
        return False
        
# ----------------- æŠ“å–è‚¡ç¥¨è³‡æ–™ -----------------
def fetch_stock_data(stock_id):
    """å¾ Supabase ç²å–è‚¡ç¥¨ OHLCV æ•¸æ“š"""
    stock_id_clean = stock_id.replace(".TW","").replace(".TWO","")
    params = {"stock_id": f"eq.{stock_id_clean}", "order": "date.asc", "select": "*, stock_name"}

    try:
        res = requests.get(
            f"{SUPABASE_URL}/rest/v1/{TABLE_NAME}", headers=headers, params=params, timeout=30
        )
        res.raise_for_status()
        data = res.json()
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data)
        df['date'] = pd.to_datetime(df['date'])
        return df
    except Exception as e:
        print(f"âš ï¸ Supabase è®€å– {stock_id} å¤±æ•—: {e}")
        return pd.DataFrame()

# ----------------- æ•¸æ“šè™•ç†æ ¸å¿ƒåŠŸèƒ½ -----------------

def convert_to_weekly(df_daily):
    """å°‡æ—¥ç·šæ•¸æ“š (OHLCV) è½‰æ›ç‚ºé€±ç·šæ•¸æ“šã€‚"""
    if df_daily.empty: return df_daily
    df = df_daily.set_index('date')
    weekly_data = df.resample('W').agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    })
    df_weekly = weekly_data.dropna(subset=['open']).reset_index()
    if not df_daily.empty and 'stock_name' in df_daily.columns:
        df_weekly['stock_name'] = df_daily['stock_name'].iloc[-1]
    if not df_daily.empty and 'stock_id' in df_daily.columns:
        df_weekly['stock_id'] = df_daily['stock_id'].iloc[-1]
    return df_weekly


def kline_merge(df):
    """Kç·šåˆä½µï¼šæ¡ç”¨æ›´ç©©å¥çš„åŒ…å«é—œä¿‚åˆ¤å®šé‚è¼¯ï¼Œè™•ç†é‚Šç•Œæƒ…æ³ã€‚ï¼ˆçºè«–ç­†æ®µé è™•ç†ï¼‰"""
    if df.empty: return df
    df_raw = df.copy().set_index('date')
    processed_kline = []
    
    current_kline = {col: df_raw.iloc[0][col] for col in ['open', 'high', 'low', 'close', 'volume']}
    current_kline['Index'] = df_raw.index[0]

    for i in range(1, len(df_raw)):
        next_row = df_raw.iloc[i]
        next_kline = {col: next_row[col] for col in ['open', 'high', 'low', 'close', 'volume']}
        
        # åŒ…å«é—œä¿‚åˆ¤å®šï¼šå¾Œä¸€æ ¹ K ç·šå®Œå…¨è¢«å‰ä¸€æ ¹ K ç·šåŒ…å«ï¼Œæˆ–å¾Œä¸€æ ¹ K ç·šå®Œå…¨åŒ…å«å‰ä¸€æ ¹ K ç·š
        is_inclusion = (
            (next_row['high'] <= current_kline['high'] and next_row['low'] >= current_kline['low']) or
            (next_row['high'] >= current_kline['high'] and next_row['low'] <= current_kline['low'])
        )
        
        if is_inclusion:
            current_kline['high'] = max(current_kline['high'], next_row['high'])
            current_kline['low'] = min(current_kline['low'], next_row['low'])
            current_kline['volume'] += next_row['volume']
            # ä¿ç•™æ–¹å‘ï¼šå¦‚æœæ˜¯åŒæ–¹å‘ï¼ˆä¾‹å¦‚éƒ½æ˜¯é™½ç·šï¼‰å‰‡å–æœ€æ–°æ”¶ç›¤åƒ¹ï¼Œä½†é€™è£¡ç°¡åŒ–ç‚ºåªå–æœ€æ–°æ”¶ç›¤åƒ¹
            current_kline['close'] = next_row['close']
            current_kline['Index'] = df_raw.index[i]
        else:
            processed_kline.append(current_kline)
            # å»ºç«‹æ–°çš„ K ç·šæ®µ
            current_kline = next_kline
            current_kline['Index'] = df_raw.index[i]
            
    processed_kline.append(current_kline)
    
    df_merged = pd.DataFrame(processed_kline).set_index('Index').rename_axis('date').reset_index()
    df_merged['date'] = pd.to_datetime(df_merged['date'])
    return df_merged


def find_divergence(df_merged):
    """åŸºç¤åˆ†å‹åˆ¤æ–·ï¼šä¸­é–“ K ç·šé«˜ä½é»å¤§æ–¼æˆ–ç­‰æ–¼å…©å´ã€‚"""
    df = df_merged.copy()
    df['H_prev'], df['H_next'] = df['high'].shift(1), df['high'].shift(-1)
    df['L_prev'], df['L_next'] = df['low'].shift(1), df['low'].shift(-1)
    # é ‚åˆ†å‹ï¼šä¸­é–“ high >= å·¦å³ high
    df['Is_Top_Divergence'] = (df['high'] >= df['H_prev']) & (df['high'] >= df['H_next'])
    # åº•åˆ†å‹ï¼šä¸­é–“ low <= å·¦å³ low
    df['Is_Bottom_Divergence'] = (df['low'] <= df['L_prev']) & (df['low'] <= df['L_next'])
    df['Is_Top_Divergence'] = df['Is_Top_Divergence'].fillna(False)
    df['Is_Bottom_Divergence'] = df['Is_Bottom_Divergence'].fillna(False)
    df['Top_Price'] = np.where(df['Is_Top_Divergence'], df['high'], np.nan)
    df['Bottom_Price'] = np.where(df['Is_Bottom_Divergence'], df['low'], np.nan)
    return df


def find_stroke_pivots(df_merged):
    """
    ğŸŒŸ åš´æ ¼ç­†æ®µåˆ¤æ–·å‡½æ•¸ã€‚ç¯©é¸å‡ºç¬¦åˆã€Œå…©åˆ†å‹ä¹‹é–“è‡³å°‘æœ‰ä¸€æ ¹éåŒ…å« K ç·šã€çš„è½‰æŠ˜é»ã€‚
    """
    df_divergence = find_divergence(df_merged.copy())
    pivot_points = df_divergence[df_divergence['Is_Top_Divergence'] | df_divergence['Is_Bottom_Divergence']].copy()

    if pivot_points.empty: return pd.DataFrame()

    # 1: é ‚åˆ†å‹, -1: åº•åˆ†å‹
    pivot_points['Type'] = np.where(pivot_points['Is_Top_Divergence'], 1, -1)
    
    final_pivots_list = []
    last_pivot_index = -1 # ç”¨ä¾†è¨˜éŒ„åœ¨ df_merged ä¸­çš„ç´¢å¼•ä½ç½®

    for idx, row in pivot_points.iterrows():
        # ç²å–ç•¶å‰åˆ†å‹åœ¨ df_merged ä¸­çš„å¯¦éš›ä½ç½®
        current_index_loc = df_merged[df_merged['date'] == row['date']].index[0]
        
        if not final_pivots_list:
            # ç¬¬ä¸€å€‹åˆ†å‹ç›´æ¥åŠ å…¥
            row['Pivot_Price_Calc'] = row['Top_Price'] if row['Type'] == 1 else row['Bottom_Price']
            final_pivots_list.append(row)
            last_pivot_index = current_index_loc
            continue
            
        last_pivot = final_pivots_list[-1]
        last_pivot_index_loc = df_merged[df_merged['date'] == last_pivot['date']].index[0]
        
        if row['Type'] == last_pivot['Type']:
            # åŒå‘åˆ†å‹ï¼Œæ ¹æ“šåƒ¹æ ¼å–æ¥µå€¼ï¼Œä¸¦æ›¿æ›æ‰å‰ä¸€å€‹åˆ†å‹
            is_new_extreme = (row['Type'] == 1 and row['Top_Price'] > last_pivot['Top_Price']) or \
                             (row['Type'] == -1 and row['Bottom_Price'] < last_pivot['Bottom_Price'])
            
            if is_new_extreme:
                # æ›´æ–°å‰ä¸€å€‹åˆ†å‹ï¼ˆæ›¿æ›ï¼‰
                # æ³¨æ„ï¼šé€™è£¡æ‡‰è©²æ›´æ–° final_pivots_list è£¡æœ€å¾Œä¸€é …çš„æ•¸æ“šï¼Œè€Œä¸æ˜¯ last_pivot
                final_pivots_list[-1].update({'date': row['date'],
                                              'Top_Price': row['Top_Price'] if row['Type'] == 1 else last_pivot['Top_Price'],
                                              'Bottom_Price': row['Bottom_Price'] if row['Type'] == -1 else last_pivot['Bottom_Price'],
                                              'Pivot_Price_Calc': row['Top_Price'] if row['Type'] == 1 else row['Bottom_Price'],
                                              'Is_Top_Divergence': row['Is_Top_Divergence'],
                                              'Is_Bottom_Divergence': row['Is_Bottom_Divergence']})
                last_pivot_index = current_index_loc
        else:
            # ç•°å‘åˆ†å‹ï¼šæª¢æŸ¥æ˜¯å¦æ»¿è¶³åš´æ ¼ç­†æ®µå®šç¾© (è‡³å°‘é–“éš”ä¸€æ ¹ K ç·šï¼Œå³ index è·é›¢ >= 2)
            kline_count_between = current_index_loc - last_pivot_index_loc
            if kline_count_between >= 2:
                row['Pivot_Price_Calc'] = row['Top_Price'] if row['Type'] == 1 else row['Bottom_Price']
                final_pivots_list.append(row)
                last_pivot_index = current_index_loc
                
    # ç”±æ–¼ last_pivot åœ¨å¾ªç’°ä¸­æ›´æ–°çš„æ˜¯å­—å…¸å¼•ç”¨ï¼Œæˆ‘å€‘éœ€è¦é‡æ–°æ§‹é€  DataFrame ä»¥ç¢ºä¿æ•¸æ“šæ­£ç¢º
    df_filtered = pd.DataFrame(final_pivots_list)

    if df_filtered.empty: return pd.DataFrame()
        
    df_filtered['date'] = pd.to_datetime(df_filtered['date'])
    df_pivot_data = df_filtered[['date', 'Type', 'Pivot_Price_Calc']].rename(columns={
        'Type': 'Pivot_Type',
        'Pivot_Price_Calc': 'Pivot_Price'
    })
    return df_pivot_data


def filter_pivots_for_stroke(df_result, df_original):
    """å°‡åˆ†å‹çµæœåˆä½µå›åŸå§‹Kç·šæ•¸æ“šï¼Œä¸¦æ‰¾å‡ºæœ€å¾Œä¸€å€‹è½‰æŠ˜é»çš„è³‡è¨Šã€‚"""
    df_original['date'] = pd.to_datetime(df_original['date'])
    
    # è™•ç†ç„¡è½‰æŠ˜é»çš„æƒ…æ³
    if df_result.empty:
        df_original['Pivot_Type'] = 0
        df_original['Pivot_Price'] = np.nan
        return df_original, None, 0

    last_pivot_row = df_result.iloc[-1]
    last_date = last_pivot_row['date']
    last_type = last_pivot_row['Pivot_Type']
    
    df_merged = df_original.merge(df_result, on='date', how='left')
    df_merged['Pivot_Type'] = df_merged['Pivot_Type'].fillna(0).astype(int)
    df_merged['Pivot_Price'] = df_merged['Pivot_Price'].fillna(np.nan)
    
    return df_merged, last_date, last_type


def analyze_trend_by_pivots(pivot_df):
    """åŸºæ–¼æœ‰æ•ˆè½‰æŠ˜é»åˆ¤æ–·é ‚åº•è¶¨å‹¢ (HH/HL)"""
    if pivot_df.empty or len(pivot_df) < 4:
        return {'Overall_Trend': "çµæ§‹æ•¸æ“šä¸è¶³ (éœ€è‡³å°‘å››å€‹æœ‰æ•ˆè½‰æŠ˜é»)"}

    # ç¢ºä¿åªä½¿ç”¨æœ€æ–°çš„ã€æœ‰æ•ˆçš„é ‚é»å’Œåº•é»
    tops = pivot_df[pivot_df['Pivot_Type'] == 1]['Pivot_Price'].dropna()
    bottoms = pivot_df[pivot_df['Pivot_Type'] == -1]['Pivot_Price'].dropna()

    if len(tops) < 2 or len(bottoms) < 2:
        return {'Overall_Trend': "çµæ§‹æ•¸æ“šä¸è¶³ (éœ€è‡³å°‘å…©å€‹é ‚é»å’Œå…©å€‹åº•é»)"}

    # å–æœ€è¿‘çš„å…©å€‹é ‚é» (T2, T1) å’Œå…©å€‹åº•é» (B2, B1)
    # T2/B2 æ˜¯æœ€æ–°çš„
    T2, T1 = tops.iloc[-1], tops.iloc[-2]
    B2, B1 = bottoms.iloc[-1], bottoms.iloc[-2]

    is_hh, is_hl = T2 > T1, B2 > B1 # Higher High, Higher Low
    is_lh, is_ll = T2 < T1, B2 < B1 # Lower High, Lower Low

    trend_result = "ç›¤æ•´/å¾…ç¢ºèª"
    if is_hh and is_hl: trend_result = "âœ… ä¸Šå‡è¶¨å‹¢ (Higher Highs & Higher Lows)"
    elif is_lh and is_ll: trend_result = "ğŸ”» ä¸‹é™è¶¨å‹¢ (Lower Highs & Lower Lows)"
    elif is_hh and is_ll: trend_result = "âš ï¸ æ“´å¼µçµæ§‹ (é«˜é»æŠ¬é«˜, ä½é»é™ä½)"
    elif is_lh and is_hl: trend_result = "â³ æ”¶æ–‚çµæ§‹ (é«˜é»é™ä½, ä½é»æŠ¬é«˜)"
        
    return {'Overall_Trend': trend_result}

def check_rebound_signal(df_full_processed, trend_period=90):
    """çµæ§‹å›èª¿èµ·æ¼²ä¿¡è™Ÿæª¢æŸ¥ (ä¸»è¦ç”¨æ–¼åˆ¤æ–·å¤šé ­å›èª¿æ˜¯å¦å‡ºç¾è²·é»)"""
    if len(df_full_processed) < trend_period + 5:
        return False, "æ•¸æ“šä¸è¶³ä»¥åˆ¤æ–·é•·ç·šè¶¨å‹¢"

    df_check = df_full_processed.iloc[-trend_period:].copy()
    pivot_df = df_check[df_check['Pivot_Type'] != 0].copy()
    current = df_check.iloc[-1]
    prev = df_check.iloc[-2]

    trend_result = analyze_trend_by_pivots(pivot_df)['Overall_Trend']
    is_high_level_trend = ('ä¸Šå‡è¶¨å‹¢' in trend_result)
    # é¡å¤– MA éæ¿¾æ¢ä»¶ï¼š60æ—¥å‡ç·šå‘ä¸Šä¸”æ”¶ç›¤åƒ¹åœ¨ 60 æ—¥å‡ç·šä¹‹ä¸Š
    is_ma_aligned = (df_check['MA60'].iloc[-1] > df_check['MA60'].iloc[0]) and (current['close'] > current['MA60'])
    
    if not (is_high_level_trend and is_ma_aligned):
        return False, f"âŒ é•·ç·šè¶¨å‹¢ä¸ç¬¦åˆ HH/HL ä¸Šå‡çµæ§‹æˆ– MA60 æ¢ä»¶ ({trend_result})"

    bottoms = pivot_df[pivot_df['Pivot_Type'] == -1]['Pivot_Price'].dropna()
    tops = pivot_df[pivot_df['Pivot_Type'] == 1]['Pivot_Price'].dropna()
    
    if len(bottoms) < 2 or len(tops) < 1:
        return False, "çµæ§‹è½‰æŠ˜é»ä¸è¶³ï¼Œç„¡æ³•å®šä½å›èª¿å€é–“"

    T_last = tops.iloc[-1]      # æœ€æ–°é«˜é»
    B_pre_T = bottoms.iloc[-2]  # å‰ä¸€å€‹ä½é» (å‰ä¸€å€‹ç­†æ®µçš„åº•éƒ¨æ”¯æ’)
    
    # æ­£åœ¨å›èª¿ä¸­ (åƒ¹æ ¼å¾é«˜é»ä¸‹ä¾†)
    is_correcting = (current['close'] < T_last)
    # å®ˆä½å‰ä¸€å€‹ä½é» (B_pre_T) çš„æ”¯æ’
    is_holding_support = (current['low'] > B_pre_T)
    
    if not (is_correcting and is_holding_support):
        if current['close'] > T_last:
            return False, "âœ… å·²ç¶“çªç ´å‰é«˜ï¼Œå›èª¿å·²çµæŸï¼Œå±¬æ–¼æ–°çš„ä¸Šæ¼²æ³¢æ®µ"
        return False, f"ğŸš¨ çµæ§‹æ€§å›èª¿å¤±æ•—ï¼šä½é»å·²è·Œç ´çµæ§‹æ”¯æ’ B_pre_T ({B_pre_T:.2f})"

    # æª¢æŸ¥ K ç·šç¢ºèªè¨Šè™Ÿï¼šçœ‹æ¼²åå™¬ (Bullish Engulfing)
    is_bullish_engulfing = (
        (current['close'] > current['open']) and  # ç•¶å¤©æ˜¯é™½ç·š
        (current['close'] > prev['open']) and  # ç•¶å¤©æ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©é–‹ç›¤åƒ¹
        (current['open'] < prev['close'])     # ç•¶å¤©é–‹ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©æ”¶ç›¤åƒ¹
    )
    # æª¢æŸ¥ K ç·šç¢ºèªè¨Šè™Ÿï¼šæ”¶ç›¤ç«™ä¸Š MA20 ä¸”çªç ´å‰ä¸€æ ¹ K ç·šé«˜é»æˆ–å½¢æˆçœ‹æ¼²åå™¬
    is_rebound_confirmed = (
        current['close'] > current['MA20']
        and (current['close'] > prev['high'] or is_bullish_engulfing)
    )

    if is_rebound_confirmed:
        return True, f"âœ… **ã€çµæ§‹å›èª¿èµ·æ¼²ä¿¡è™Ÿã€‘**ï¼šåƒ¹æ ¼åœ¨ B_pre_T æ”¯æ’ä¸Šç¢ºèªåè½‰ï¼(æ”¯æ’ä½: {B_pre_T:.2f})"
    else:
        return False, f"ğŸ’¡ **æ½›åœ¨èµ·æ¼²æç¤º**ï¼šçµæ§‹å·²ç¢ºèªç‚ºå¥åº·å›èª¿å€é–“ ({B_pre_T:.2f} æ”¯æ’), ç­‰å¾…å¼·å‹¢ K ç·šç¢ºèªèµ·æ¼²ï¼"


import pandas as pd
import numpy as np

# ----------------- ğŸŒŸ NEW: ä¸»åŠ›è¡Œç‚ºåµæ¸¬æ ¸å¿ƒå‡½æ•¸ -----------------
def detect_smart_money_signals(df_tech, vsa_vol_multiplier=2, rsi_period=14):
    """
    ä¸»åŠ›è¡Œç‚ºåµæ¸¬ - åˆ¤æ–·æ½›åœ¨çš„ä¸»åŠ›æ‹‰æŠ¬ (è²·å…¥) å’Œæ‹‹å”® (è³£å‡º) è¨Šè™Ÿã€‚
    """
    df = df_tech.copy()
    df.reset_index(drop=True, inplace=True) # ç¢ºä¿ç´¢å¼•é€£çºŒ

    # --- è¨ˆç®—åŸºç¤æŒ‡æ¨™ (RSI, VWAP, VOL20) ---
    df['TP'] = (df['high'] + df['low'] + df['close']) / 3
    df['VOL20'] = df['volume'].rolling(20).mean()
    df['TPV'] = df['TP'] * df['volume']
    
    # VWAP ç´¯ç©è¨ˆç®—
    df['VWAP'] = df['TPV'].cumsum() / df['volume'].cumsum()
    
    # RSI
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.ewm(com=rsi_period - 1, adjust=False).mean()
    avg_loss = loss.ewm(com=rsi_period - 1, adjust=False).mean()
    rs = avg_gain / avg_loss.replace(0, 1e-9)
    df['RSI'] = 100 - (100 / (1 + rs))

    # K ç·šå½¢æ…‹èˆ‡é‡èƒ½
    df['Body_Ratio'] = (df['close'] - df['open']).abs() / (df['high'] - df['low']).replace(0, 1e-6)
    is_high_volume = df['volume'] >= (df['VOL20'] * vsa_vol_multiplier)
    
    # ----------------------------------------------------
    # --- å¤šé ­è¨Šè™Ÿ (Buy Signals) ---
    # ----------------------------------------------------
    
    # --- 1. VSA å¼·å‹¢æ‹‰æŠ¬ (å¸ç±Œ) ---
    is_long_bull_k = (df['close'] > df['open']) & (df['Body_Ratio'] > 0.6) # é™½ç·šä¸”å¯¦é«”é£½æ»¿
    df['Signal_VSA_Strong'] = np.where(is_long_bull_k & is_high_volume, df['low'] * 0.99, np.nan)
    
    # --- 2. ä¸»åŠ›æˆæœ¬çªç ´è¨Šè™Ÿï¼šæ”¶ç›¤ç«™ä¸Š VWAP ---
    df['Signal_VWAP_Break'] = np.where(
        (df['close'] > df['VWAP']) & (df['close'].shift(1).fillna(-np.inf) <= df['VWAP'].shift(1).fillna(-np.inf)),
        df['low'] * 0.995,
        np.nan
    )
    
    # ----------------------------------------------------
    # --- æ–°å¢ï¼šç©ºé ­è¨Šè™Ÿ (Sell Signals) ---
    # ----------------------------------------------------
    
    # --- 4. VSA ææ…Œæ‹‹å”® (æ´¾ç™¼/å‡ºè²¨) ---
    is_long_bear_k = (df['close'] < df['open']) & (df['Body_Ratio'] > 0.6) # é™°ç·šä¸”å¯¦é«”é£½æ»¿
    # æ¨™è¨˜åœ¨ K ç·šé ‚éƒ¨
    df['Signal_VSA_Weak'] = np.where(is_long_bear_k & is_high_volume, df['high'] * 1.01, np.nan)

    # --- 5. ä¸»åŠ›æˆæœ¬è·Œç ´è¨Šè™Ÿï¼šæ”¶ç›¤è·Œç ´ VWAP ---
    # åˆ¤æ–·ä»Šæ—¥æ”¶ç›¤åƒ¹è·Œç ´ VWAPï¼Œä¸”æ˜¨æ—¥æ”¶ç›¤åƒ¹åœ¨ VWAP ä¹‹ä¸Š (è·Œç ´)
    df['Signal_VWAP_BreakDown'] = np.where(
        (df['close'] < df['VWAP']) & (df['close'].shift(1).fillna(np.inf) >= df['VWAP'].shift(1).fillna(np.inf)),
        df['high'] * 1.005, # æ¨™è¨˜åœ¨ K ç·šé ‚éƒ¨é™„è¿‘
        np.nan
    )
    
    # ----------------------------------------------------
    # --- 3. èƒŒé›¢è¨Šè™Ÿ (Divergence & TopDivergence) ---
    # ----------------------------------------------------
    divergence_signal = [np.nan] * len(df)
    top_divergence_signal = [np.nan] * len(df)
    
    # æ‰¾å‡ºåº•åˆ†å‹å’Œé ‚åˆ†å‹
    df['Temp_Bottom_Pivot'] = (df['low'].shift(-1) > df['low']) & (df['low'].shift(1) > df['low'])
    df['Temp_Top_Pivot'] = (df['high'].shift(-1) < df['high']) & (df['high'].shift(1) < df['high'])
    
    bottom_pivots = df[df['Temp_Bottom_Pivot']].copy()
    top_pivots = df[df['Temp_Top_Pivot']].copy()

    # --- åº•éƒ¨èƒŒé›¢ (Signal_Divergence) ---
    if len(bottom_pivots) >= 2:
        for i in range(1, len(bottom_pivots)):
            B2_idx = bottom_pivots.index[i]
            B1_idx = bottom_pivots.index[i-1]
            
            is_price_ll = df.loc[B2_idx, 'low'] < df.loc[B1_idx, 'low']
            is_rsi_hh = df.loc[B2_idx, 'RSI'] > df.loc[B1_idx, 'RSI']

            if is_price_ll and is_rsi_hh:
                divergence_signal[B2_idx] = df.loc[B2_idx, 'low'] * 0.998

    # --- æ–°å¢ï¼šé ‚éƒ¨èƒŒé›¢ (Signal_TopDivergence) ---
    if len(top_pivots) >= 2:
        for i in range(1, len(top_pivots)):
            T2_idx = top_pivots.index[i]
            T1_idx = top_pivots.index[i-1]
            
            # ç¢ºèªåƒ¹æ ¼é ‚é ‚é«˜ (Price High Higher)
            is_price_hh = df.loc[T2_idx, 'high'] > df.loc[T1_idx, 'high']
            # ç¢ºèª RSI é ‚åº•ä½ (RSI Low Lower)
            is_rsi_ll = df.loc[T2_idx, 'RSI'] < df.loc[T1_idx, 'RSI']

            if is_price_hh and is_rsi_ll:
                top_divergence_signal[T2_idx] = df.loc[T2_idx, 'high'] * 1.002
        
    df['Signal_Divergence'] = pd.Series(divergence_signal, index=df.index)
    df['Signal_TopDivergence'] = pd.Series(top_divergence_signal, index=df.index)
    
    # ----------------------------------------------------
    # --- è¨Šè™Ÿå„ªå…ˆç´šæ¸…ç† (é¿å…å¤šç©ºè¨Šè™Ÿè¡çª) ---
    # ----------------------------------------------------
    
    is_any_strong_buy = df['Signal_VSA_Strong'].notna() | df['Signal_VWAP_Break'].notna()
    is_any_strong_sell = df['Signal_VSA_Weak'].notna() | df['Signal_VWAP_BreakDown'].notna()

    # 1. è²·å…¥è¨Šè™Ÿå„ªå…ˆï¼šå¼·å‹¢è²·å…¥æ—¥æ¸…é™¤æ‰€æœ‰çœ‹è·Œ/è³£å‡ºè¨Šè™Ÿ
    df.loc[is_any_strong_buy, 'Signal_VSA_Weak'] = np.nan
    df.loc[is_any_strong_buy, 'Signal_VWAP_BreakDown'] = np.nan
    df.loc[is_any_strong_buy, 'Signal_TopDivergence'] = np.nan
    
    # 2. è³£å‡ºè¨Šè™Ÿå„ªå…ˆï¼šå¼·å‹¢è³£å‡ºæ—¥æ¸…é™¤æ‰€æœ‰çœ‹æ¼²/è²·å…¥è¨Šè™Ÿ
    df.loc[is_any_strong_sell, 'Signal_VSA_Strong'] = np.nan
    df.loc[is_any_strong_sell, 'Signal_VWAP_Break'] = np.nan
    df.loc[is_any_strong_sell, 'Signal_Divergence'] = np.nan
    
    # æœ€çµ‚å›å‚³æ‰€æœ‰è¨Šè™Ÿæ¬„ä½
    return df[['date', 
               'Signal_VSA_Strong', 'Signal_VWAP_Break', 'Signal_Divergence', 
               'Signal_VSA_Weak', 'Signal_VWAP_BreakDown', 'Signal_TopDivergence']]
# ----------------- æ•´åˆç”Ÿæˆåœ–è¡¨ (å«è¶¨å‹¢åˆ†æå’Œè¨Šè™Ÿæª¢æŸ¥) -----------------
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# å‡è¨­ä»¥ä¸‹å‡½æ•¸å·²å®šç¾©ä¸¦å¯ä½¿ç”¨ï¼š
# fetch_stock_data, convert_to_weekly, kline_merge, find_stroke_pivots, 
# filter_pivots_for_stroke, detect_smart_money_signals, analyze_trend_by_pivots, 
# check_rebound_signal 

# ----------------- æ•´åˆç”Ÿæˆåœ–è¡¨ (å«è¶¨å‹¢åˆ†æå’Œè¨Šè™Ÿæª¢æŸ¥) -----------------
def generate_chart(stock_id_clean, start_date=None, end_date=None, simple_mode=False, num_rows=30, frequency='D'):
    """ç”ŸæˆåŒ…å« K ç·šåœ–ã€çºè«–ç­†æ®µã€æŠ€è¡“æŒ‡æ¨™å’Œä¸»åŠ›è¨Šè™Ÿçš„ Plotly åœ–è¡¨ã€‚"""
    
    df_original = fetch_stock_data(stock_id_clean)
    if df_original.empty: return None, f"{stock_id_clean} ç„¡è³‡æ–™", "N/A", "N/A", "neutral"

    df_full = df_original.copy()
    
    if frequency == 'W': df_full = convert_to_weekly(df_full)
    
    if start_date and end_date:
        df_full = df_full[
            (df_full['date'] >= pd.to_datetime(start_date)) &
            (df_full['date'] <= pd.to_datetime(end_date))
        ]

    if df_full.empty: return None, f"{stock_id_clean} åœ¨ {start_date} ~ {end_date} ç„¡è³‡æ–™", "N/A", "N/A", "neutral"

    # --- 1. æŠ€è¡“æŒ‡æ¨™è¨ˆç®— ---
    df_tech = df_full.copy()
    df_tech['TP'] = (df_tech['high'] + df_tech['low'] + df_tech['close']) / 3
    # å¢åŠ ç§»å‹•å¹³å‡ç·š
    for ma in [5, 10, 20, 60]: df_tech[f"MA{ma}"] = df_tech['close'].rolling(ma).mean()
    # å¢åŠ æˆäº¤é‡å‡ç·š
    df_tech['VOL5'] = df_tech['volume'].rolling(5).mean()
    df_tech['VOL20'] = df_tech['volume'].rolling(20).mean()
    # ATR (å¹³å‡çœŸå¯¦æ³¢å¹…) è¨ˆç®—
    df_tech['H-L'], df_tech['H-PC'], df_tech['L-PC'] = df_tech['high'] - df_tech['low'], abs(df_tech['high'] - df_tech['close'].shift(1)), abs(df_tech['low'] - df_tech['close'].shift(1))
    df_tech['TR'] = df_tech[['H-L', 'H-PC', 'L-PC']].max(axis=1)
    df_tech['ATR14'] = df_tech['TR'].rolling(14).mean().round(3)
    df_tech['stop_loss'] = df_tech['low'] - df_tech['ATR14'].fillna(0) # ç°¡åŒ–æ­¢æåƒ¹
    
    # --- 2. çºè«–ç­†æ®µè½‰æŠ˜é»è™•ç† ---
    df_merged = kline_merge(df_tech.copy())
    df_pivot_data = find_stroke_pivots(df_merged.copy())
    df_final, last_pivot_date, last_pivot_type = filter_pivots_for_stroke(df_pivot_data, df_tech.copy())

    # --- ğŸŒŸ ä¸»åŠ›ä¿¡è™Ÿåµæ¸¬ ---
    df_smart_signals = detect_smart_money_signals(df_final.copy()) 
    df_final = df_final.merge(df_smart_signals, on='date', how='left')
    
    # --- 3. è¶¨å‹¢åˆ†æèˆ‡ä¿¡è™Ÿæª¢æŸ¥ ---
    df_display = df_final.tail(num_rows).copy()
    pivot_df_full = df_final[df_final['Pivot_Type'] != 0].copy()
    
    trend_analysis = analyze_trend_by_pivots(pivot_df_full)
    is_rebound, rebound_desc = check_rebound_signal(df_final)

    trend_desc_final = trend_analysis['Overall_Trend']
    
    # è¶¨å‹¢åˆ†é¡ (ç”¨æ–¼å‰ç«¯é¡è‰²é¡¯ç¤º)
    trend_class = 'neutral'
    if 'ä¸‹é™è¶¨å‹¢' in trend_desc_final or 'ä¸‹ç©¿å‰åº•' in trend_desc_final:
        trend_class = 'bearish'
    elif 'ä¸Šå‡è¶¨å‹¢' in trend_desc_final or 'ä¸Šç©¿å‰é«˜' in trend_desc_final:
        trend_class = 'bullish'
        
    # ğŸŒŸ VWAPï¼šé‡æ–°è¨ˆç®—ï¼Œåƒ…é™æ–¼ df_display ç¯„åœ (ç¢ºä¿é¡¯ç¤ºçš„ VWAP æ˜¯ç›¸å°çš„)
    df_display['TPV_display'] = df_display['TP'] * df_display['volume']
    df_display['VWAP'] = df_display['TPV_display'].cumsum() / df_display['volume'].cumsum()
    
    # --- 4. ç¹ªè£½åœ–è¡¨ ---
    min_price = df_display[['low', 'MA5', 'MA10', 'MA20', 'MA60', 'VWAP']].min(skipna=True).min(skipna=True)
    max_price = df_display[['high', 'MA5', 'MA10', 'MA20', 'MA60', 'VWAP']].max(skipna=True).max(skipna=True)
    
    if pd.isna(min_price) or pd.isna(max_price) or min_price == max_price:
        min_price = df_display['close'].min()
        max_price = df_display['close'].max()

    price_range = max_price - min_price
    yaxis_min = min_price - price_range * 0.2 
    yaxis_max = max_price + price_range * 0.2 

    fig = make_subplots(
        rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.07,
        row_heights=[0.7, 0.15, 0.15],
        subplot_titles=(f"Kç·šåœ– ({frequency}ç·š, å«çºè«–ç­†æ®µ)", "æˆäº¤é‡", "ATR")
    )

    # Kç·šåœ–èˆ‡æŒ‡æ¨™
    fig.add_trace(go.Candlestick(x=df_display['date'], open=df_display['open'], high=df_display['high'], low=df_display['low'], close=df_display['close'], increasing_line_color='red', decreasing_line_color='green', name=f'{frequency}ç·š'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['stop_loss'], mode='lines', line=dict(dash='dot', color='gray'), name='æ­¢æåƒ¹'), row=1, col=1)
    ma_colors = {5: 'blue', 10: 'orange', 20: 'purple', 60: 'black'}
    for ma in [5, 10, 20, 60]: fig.add_trace(go.Scatter(x=df_display['date'], y=df_display[f"MA{ma}"], mode='lines', line=dict(color=ma_colors[ma], width=1), name=f"MA{ma}"), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VWAP'], mode='lines', line=dict(color='magenta', width=2, dash='solid'), name='ä¸»åŠ›æˆæœ¬ç·š (VWAP)'), row=1, col=1)

    # ----------------------------------------------------
    # ğŸŒŸ è²·å…¥è¨Šè™Ÿ (æ¨™è¨˜åœ¨ K ç·šä¸‹æ–¹)
    # ----------------------------------------------------
    
    # VSA å¼·å‹¢æ‹‰æŠ¬
    fig.add_trace(go.Scatter(
        x=df_display['date'],
        y=df_display['Signal_VSA_Strong'],
        mode='markers',
        marker=dict(size=12, symbol='star-triangle-up', color='red', line=dict(width=1, color='black')),
        name='VSA å¼·å‹¢æ‹‰æŠ¬',
        hovertext="ä¸»åŠ›VSAå¼·å‹¢æ‹‰æŠ¬",
        hoverinfo='text'
    ), row=1, col=1)

    # VWAP æˆæœ¬çªç ´
    fig.add_trace(go.Scatter(
        x=df_display['date'],
        y=df_display['Signal_VWAP_Break'],
        mode='markers',
        marker=dict(size=10, symbol='triangle-up', color='orange', line=dict(width=1, color='black')),
        name='VWAP æˆæœ¬çªç ´',
        hovertext="ä¸»åŠ›æˆæœ¬çªç ´",
        hoverinfo='text'
    ), row=1, col=1)

    # ğŸŒŸ NEW: åŠ å…¥ RSI åº•èƒŒé›¢å¸ç±Œä¿¡è™Ÿ (èª¿æ•´ Y åº§æ¨™)
    offset_divergence = df_display['ATR14'] * 0.2
    y_divergence_adjusted = df_display['Signal_Divergence'] - offset_divergence
    
    fig.add_trace(go.Scatter(
        x=df_display['date'],
        y=y_divergence_adjusted,
        mode='markers',
        marker=dict(size=10, symbol='diamond', color='blue', line=dict(width=1, color='black')),
        name='RSI åº•èƒŒé›¢ (å¸ç±Œ)',
        hovertext="RSIåº•èƒŒé›¢å¸ç±Œ",
        hoverinfo='text'
    ), row=1, col=1)

    # ----------------------------------------------------
    # ğŸŒŸ è³£å‡ºè¨Šè™Ÿ (æ¨™è¨˜åœ¨ K ç·šä¸Šæ–¹)
    # ----------------------------------------------------
    
    # VSA ææ…Œæ‹‹å”®
    fig.add_trace(go.Scatter(
        x=df_display['date'],
        y=df_display['Signal_VSA_Weak'],
        mode='markers',
        marker=dict(size=12, symbol='star-triangle-down', color='green', line=dict(width=1, color='black')),
        name='VSA ææ…Œæ‹‹å”®',
        hovertext="ä¸»åŠ›VSAææ…Œæ‹‹å”®",
        hoverinfo='text'
    ), row=1, col=1)
    
    # VWAP æˆæœ¬è·Œç ´
    fig.add_trace(go.Scatter(
        x=df_display['date'],
        y=df_display['Signal_VWAP_BreakDown'],
        mode='markers',
        marker=dict(size=10, symbol='triangle-down', color='purple', line=dict(width=1, color='black')),
        name='VWAP æˆæœ¬è·Œç ´',
        hovertext="ä¸»åŠ›æˆæœ¬è·Œç ´",
        hoverinfo='text'
    ), row=1, col=1)
    
    # ğŸŒŸ NEW: åŠ å…¥ RSI é ‚èƒŒé›¢æ´¾ç™¼ä¿¡è™Ÿ (èª¿æ•´ Y åº§æ¨™)
    offset_top_divergence = df_display['ATR14'] * 0.2
    y_top_divergence_adjusted = df_display['Signal_TopDivergence'] + offset_top_divergence
    
    fig.add_trace(go.Scatter(
        x=df_display['date'],
        y=y_top_divergence_adjusted, # ä½¿ç”¨èª¿æ•´å¾Œçš„åº§æ¨™
        mode='markers',
        marker=dict(size=10, symbol='diamond', color='green', line=dict(width=1, color='black')),
        name='RSI é ‚èƒŒé›¢ (æ´¾ç™¼)',
        hovertext="RSIé ‚èƒŒé›¢æ´¾ç™¼",
        hoverinfo='text'
    ), row=1, col=1)
    
    # ----------------------------------------------------
    # æˆäº¤é‡ & ATR
    # ----------------------------------------------------
    vol_color = df_display.apply(lambda row: 'red' if row['close'] > row['open'] else ('green' if row['close'] < row['open'] else 'gray'), axis=1)
    fig.add_trace(go.Bar(x=df_display['date'], y=df_display['volume'] / 1000, name='æˆäº¤é‡ (K)', marker_color=vol_color), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VOL5'] / 1000, mode='lines', line=dict(color='blue', width=1), name='VOL5 (K)'), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VOL20'] / 1000, mode='lines', line=dict(color='orange', width=1), name='VOL20 (K)'), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['ATR14'], mode='lines', line=dict(color='red', width=1), name='ATR14'), row=3, col=1)
    
    # ğŸŒŸ åš´æ ¼ç­†æ®µæ¨™è¨˜å’ŒæŠ˜ç·š (å¯¦æ™‚å»¶ä¼¸ç­†æ®µ) (ä¿æŒä¸è®Š)
    df_pivots_display_filtered = pivot_df_full[
        (pivot_df_full['date'] >= df_display['date'].min()) &
        (pivot_df_full['date'] <= df_display['date'].max())
    ].dropna(subset=['Pivot_Price']).copy()

    # è™•ç†ç­†æ®µé€£ç·šçš„é‚è¼¯ (ç•¥ï¼Œèˆ‡åŸç¢¼ç›¸åŒ)
    extend_points = pd.DataFrame(columns=['date', 'Pivot_Price'])
    
    if last_pivot_date and not df_display.empty:
        start_index = df_display[df_display['date'] == last_pivot_date].index
        
        if not start_index.empty:
            start_index = start_index[0]
            df_extension = df_display.loc[start_index:].copy()
            current_trend_status = trend_analysis['Overall_Trend']
            
            # ç­†æ®µå»¶ä¼¸çš„åƒ¹æ ¼é»
            if last_pivot_type == 1: # ä¸Šä¸€å€‹æ˜¯é ‚é»ï¼Œç¾åœ¨å»¶ä¼¸æ‡‰å– Low
                df_extension['Pivot_Price_Extension'] = df_extension['low']
                # æª¢æŸ¥æ˜¯å¦ä¸‹ç©¿å‰ä¸€å€‹åº•
                if len(df_pivots_display_filtered) >= 2:
                    B_pre = df_pivots_display_filtered.iloc[-2]['Pivot_Price']
                    if df_extension['low'].min() < B_pre:
                        current_trend_status = "âš ï¸ **æ½›åœ¨è¶¨å‹¢åè½‰/æŒçºŒä¸‹é™ (ä¸‹ç©¿å‰åº•)**"
            elif last_pivot_type == -1: # ä¸Šä¸€å€‹æ˜¯åº•é»ï¼Œç¾åœ¨å»¶ä¼¸æ‡‰å– High
                df_extension['Pivot_Price_Extension'] = df_extension['high']
                # æª¢æŸ¥æ˜¯å¦ä¸Šç©¿å‰ä¸€å€‹é ‚
                if len(df_pivots_display_filtered) >= 2:
                    T_pre = df_pivots_display_filtered.iloc[-2]['Pivot_Price']
                    if df_extension['high'].max() > T_pre:
                        current_trend_status = "âœ… **è¶¨å‹¢æŒçºŒ (ä¸Šç©¿å‰é«˜)**"
            
            if 'Pivot_Price_Extension' in df_extension.columns:
                # ç¢ºä¿å»¶ä¼¸ç·šçš„ç¬¬ä¸€é»æ˜¯æœ€å¾Œä¸€å€‹è½‰æŠ˜é»çš„åƒ¹æ ¼
                df_extension.loc[start_index, 'Pivot_Price_Extension'] = df_pivots_display_filtered.iloc[-1]['Pivot_Price']
                extend_points = df_extension[['date', 'Pivot_Price_Extension']].rename(columns={'Pivot_Price_Extension': 'Pivot_Price'})

            trend_analysis['Overall_Trend'] = current_trend_status
            trend_desc_final = current_trend_status # æ›´æ–°åœ–è¡¨æ¨™é¡Œ
            
    if not df_pivots_display_filtered.empty:
        plot_points = df_pivots_display_filtered[['date', 'Pivot_Price']].copy()
        
        # åˆä½µå»¶ä¼¸é»
        if not extend_points.empty:
            start_date_filter = plot_points['date'].max()
            # åªå–å»¶ä¼¸é»ä¸­æ—¥æœŸå¤§æ–¼ç­‰æ–¼æœ€å¾Œä¸€å€‹è½‰æŠ˜é»æ—¥æœŸçš„éƒ¨åˆ†
            new_extension = extend_points[extend_points['date'] >= start_date_filter]
            plot_points = pd.concat([plot_points, new_extension], ignore_index=True).drop_duplicates(subset=['date'], keep='last')
            
        fig.add_trace(go.Scatter(
            x=plot_points['date'],
            y=plot_points['Pivot_Price'],
            mode='lines',
            line=dict(color='black', width=2, dash='solid'),
            name='ç­†æ®µè¶¨å‹¢é€£ç·š (åš´æ ¼ç­†æ®µ)'
        ), row=1, col=1)

        # æ¨™è¨˜é ‚é»å’Œåº•é»
        df_top = df_pivots_display_filtered[df_pivots_display_filtered['Pivot_Type']==1]
        fig.add_trace(go.Scatter(
            x=df_top['date'], y=df_top['Pivot_Price'], mode='markers',
            marker=dict(size=8, color='black', symbol='circle', line=dict(width=1, color='black')),
            name='ç­†æ®µé ‚é»', hoverinfo='text',
            text=[f"ç­†æ®µé ‚: {p:.2f}" for p in df_top['Pivot_Price']], uid='top_pivot_marker',
        ), row=1, col=1)
        
        df_bottom = df_pivots_display_filtered[df_pivots_display_filtered['Pivot_Type']==-1]
        fig.add_trace(go.Scatter(
            x=df_bottom['date'], y=df_bottom['Pivot_Price'], mode='markers',
            marker=dict(size=8, color='black', symbol='circle', line=dict(width=1, color='black')),
            name='ç­†æ®µåº•é»', hoverinfo='text',
            text=[f"ç­†æ®µåº•: {p:.2f}" for p in df_bottom['Pivot_Price']], uid='bottom_pivot_marker',
        ), row=1, col=1)
        
    stock_name = df_display['stock_name'].iloc[0] if 'stock_name' in df_display.columns and not df_display.empty else stock_id_clean
    first_date = df_display['date'].iloc[0].strftime("%Y-%m-%d")
    last_date = df_display['date'].iloc[-1].strftime("%Y-%m-%d")

    fig.update_layout(
        title=dict(
            text=f"{stock_id_clean} ({stock_name}) - {frequency}ç·šè¶¨å‹¢: {trend_desc_final} ({first_date} ~ {last_date})",
            x=0.5, xanchor='center'
        ),
        xaxis_rangeslider_visible=False, hovermode='x unified', dragmode='drawline',
        newshape=dict(line_color='black', line_width=2),
        modebar_add=['drawline', 'drawopenpath', 'drawrect', 'drawcircle', 'eraseshape'],
        yaxis=dict(range=[yaxis_min, yaxis_max]),
        height=1200
    )

    # ç¢ºä¿æˆäº¤é‡ y è»¸æ¨™ç±¤æ˜¯ K
    fig.update_yaxes(title_text="æˆäº¤é‡ (K)", row=2, col=1)
    
    html = fig.to_html(include_plotlyjs='cdn')
    
    return html, None, trend_desc_final, rebound_desc, trend_class
# ----------------- Flask è·¯ç”±éƒ¨åˆ† -----------------

# ----------------- è¼”åŠ©å‡½æ•¸éƒ¨åˆ† (ç¢ºä¿å¯ä»¥è¨ªå• SUPABASE_URL, FAVORITE_TABLE, headers, requests) -----------------

def is_favorite(stock_id):
    """
    æª¢æŸ¥æŒ‡å®š stock_id æ˜¯å¦å·²åœ¨ FAVORITE_TABLE ä¸­ã€‚
    é€™æ˜¯ç‚ºäº†åœ¨æ¸²æŸ“ chart.html æ™‚ï¼Œç‚º is_favorite è®Šæ•¸æä¾›åˆå§‹å€¼ã€‚
    """
    try:
        # æŸ¥è©¢ Supabase æª¢æŸ¥è©²è‚¡ç¥¨ ID æ˜¯å¦å­˜åœ¨
        res = requests.get(
            f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", 
            headers=headers, 
            params={"stock_id": f"eq.{stock_id}", "select": "stock_id"}
        )
        res.raise_for_status()
        # å¦‚æœè¿”å›çš„ JSON åˆ—è¡¨é•·åº¦å¤§æ–¼ 0ï¼Œå‰‡è¡¨ç¤ºå·²åŠ å…¥æœ€æ„›
        return len(res.json()) > 0
    except Exception:
        # æŸ¥è©¢å¤±æ•—æ™‚ï¼Œè¿”å› False ä»¥ä¿éšª
        return False

# ----------------- Flask è·¯ç”±éƒ¨åˆ† -----------------

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/query', methods=['POST'])
def query():
    stock_id = request.form['stock_id'].strip()
    simple_mode = request.form.get('simple_mode') == '1'
    num_rows = request.form.get('num_rows', type=int, default=30)
    frequency = request.form.get('frequency', 'D')
    
    chart_html, error, trend_desc, rebound_desc, trend_class = generate_chart(stock_id, simple_mode=simple_mode, num_rows=num_rows, frequency=frequency)
    
    if error: return f"<h2>{error}</h2><a href='/'>è¿”å›</a>"
    
    # ğŸŒŸ ä½¿ç”¨å‰é¢å®šç¾©çš„å‡½æ•¸ç²å–æœ€æ„›ç‹€æ…‹
    fav_status = is_favorite(stock_id) 
    
    return render_template(
        'chart.html', 
        chart_html=chart_html, 
        stock_id=stock_id, 
        stock_list=stock_id, 
        current_index=0, 
        simple_mode=simple_mode, 
        num_rows=num_rows, 
        is_favorite=fav_status,
        trend_desc=trend_desc,
        rebound_desc=rebound_desc,
        trend_class=trend_class,
        frequency=frequency
    )

@app.route('/chart/<stock_id>/')
@app.route('/chart/<stock_id>')
def chart_from_list(stock_id):
    stock_id = stock_id.strip()
    simple_mode = request.args.get('simple_mode') == '1'
    num_rows = request.args.get('num_rows', type=int, default=30)
    stock_list = request.args.get('list', '')
    index = request.args.get('index', type=int, default=0)
    frequency = request.args.get('frequency', 'D')

    stock_ids = stock_list.split(',') if stock_list else [stock_id]
    index = max(0, min(index, len(stock_ids)-1))

    current_stock = stock_ids[index]
    chart_html, error, trend_desc, rebound_desc, trend_class = generate_chart(current_stock, simple_mode=simple_mode, num_rows=num_rows, frequency=frequency)
    
    if error: return f"<h2>{error}</h2><a href='/'>è¿”å›</a>"
    
    # ğŸŒŸ ä½¿ç”¨å‰é¢å®šç¾©çš„å‡½æ•¸ç²å–æœ€æ„›ç‹€æ…‹
    fav_status = is_favorite(current_stock)

    return render_template(
        'chart.html', 
        chart_html=chart_html, 
        stock_id=current_stock, 
        stock_list=','.join(stock_ids), 
        current_index=index, 
        simple_mode=simple_mode, 
        num_rows=num_rows, 
        is_favorite=fav_status,
        trend_desc=trend_desc,
        rebound_desc=rebound_desc,
        trend_class=trend_class,
        frequency=frequency
    )

# ----------------- Filter åŠ Favorite è·¯ç”± -----------------
@app.route('/filter', methods=['POST'])
def filter_stocks():
    volume_min = request.form.get('volume_min', type=float, default=0)
    trend_type = request.form.get('trend_type', '')
    adr14_min = request.form.get('change_min', type=float, default=0)
    simple_mode = request.form.get('simple_mode') == '1'
    num_rows = request.form.get('num_rows', type=int, default=60)
    recent_days = request.form.get('recent_days', type=int, default=30)
    frequency = request.form.get('frequency', 'D')

    recent_date = (datetime.today() - timedelta(days=recent_days)).strftime("%Y-%m-%d")
    all_data = []
    limit = 1000
    offset = 0

    while True:
        try:
            res = requests.get(f"{SUPABASE_URL}/rest/v1/quick_view", headers=headers,
                params={
                    "latest_volume": f"gte.{int(volume_min)}",
                    "adr14": f"gte.{adr14_min}",
                    "latest_date": f"gte.{recent_date}",
                    "trend": f"eq.{trend_type}" if trend_type else None,
                    "order": "latest_date.desc", "limit": limit, "offset": offset, "select": "*"
                }, timeout=30
            )
            res.raise_for_status()
            data = res.json()
            if not data: break
            all_data.extend(data)
            if len(data) < limit: break
            offset += limit
        except Exception as e: return f"<h2>Supabase è®€å– QUICK_VIEW å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"

    if not all_data: return "<h2>æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨</h2><a href='/'>è¿”å›</a>"
    df = pd.DataFrame(all_data)
    stock_ids = [str(sid) for sid in df['stock_id']]
    count = len(df); list_param = urllib.parse.quote(','.join(stock_ids))
    
    html = (f"<h2>ç¯©é¸çµæœï¼ˆå…± {count} ç­†ï¼‰</h2>" "<table border='1' cellpadding='6' style='margin-left:0; text-align:left;'>" "<thead><tr>" "<th>è‚¡ç¥¨ä»£è™Ÿ</th><th>è‚¡ç¥¨åç¨±</th><th>æˆäº¤é‡</th>" "<th>ADR14(%)</th><th>14å¤©å¹³å‡æˆäº¤é‡</th><th>è¶¨å‹¢</th>" "</tr></thead><tbody>")
    for idx, row in df.iterrows():
        simple_param = "1" if simple_mode else "0"
        html += (f"<tr>"  
                    f"<td><a href='/chart/{row['stock_id']}?simple_mode={simple_param}&num_rows={num_rows}&list={list_param}&index={idx}&frequency={frequency}'>{row['stock_id']}</a></td>"  
                    f"<td>{row['stock_name']}</td>"  
                    f"<td>{int(row['latest_volume'])}</td>"  
                    f"<td>{row['adr14']:.2f}</td>"  
                    f"<td>{int(row['avg_volume_14'])}</td>"  
                    f"<td>{row['trend']}</td>"  
                    f"</tr>")
    html += "</tbody></table><br><a href='/'>è¿”å›</a>"
    return html

@app.route('/favorites', methods=['GET', 'POST']) # ğŸŒŸ å…è¨± GET è«‹æ±‚ï¼Œä»¥ä¾¿é€šéé€£çµè¨ªå•
def favorites_page():
    # çµ±ä¸€å¾ request.values ä¸­ç²å–åƒæ•¸ï¼Œå…¼å®¹ GET å’Œ POST
    simple_mode = request.values.get('simple_mode') == '1'
    num_rows = request.values.get('num_rows', type=int, default=30)
    frequency = request.values.get('frequency', 'D')
    
    try:
        res = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers); res.raise_for_status(); fav_data = res.json()
    except Exception as e: return f"<h2>è®€å–æœ€æ„›è‚¡ç¥¨å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"
    if not fav_data: return "<h2>å°šç„¡æœ€æ„›è‚¡ç¥¨</h2><a href='/'>è¿”å›</a>"
    stock_ids = [item['stock_id'] for item in fav_data]
    try:
        res_qv = requests.get(f"{SUPABASE_URL}/rest/v1/quick_view", headers=headers, params={"stock_id": f"in.({','.join(stock_ids)})", "order": "latest_date.desc", "select": "*"})
        res_qv.raise_for_status(); qv_data = res_qv.json()
    except Exception as e: return f"<h2>è®€å–æœ€æ„›è‚¡ç¥¨å¿«ç…§è³‡æ–™å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"

    df_qv = pd.DataFrame(qv_data); count = len(df_qv); list_param = urllib.parse.quote(','.join(stock_ids))
    
    html = (f"<h2>æˆ‘çš„æœ€æ„›ï¼ˆå…± {count} ç­†ï¼‰</h2>" "<form method='post' action='/favorites_clear' " "onsubmit=\"return confirm('ç¢ºå®šè¦åˆªé™¤æ‰€æœ‰æœ€æ„›å—ï¼Ÿ');\">" "<button type='submit' style='margin-bottom:10px;'>åˆªé™¤å…¨éƒ¨æœ€æ„›</button>" "</form>" "<table border='1' cellpadding='6' style='margin-left:0; text-align:left;'>" "<thead><tr>" "<th>è‚¡ç¥¨ä»£è™Ÿ</th><th>è‚¡ç¥¨åç¨±</th><th>æˆäº¤é‡</th>" "<th>ADR14(%)</th><th>14å¤©å¹³å‡æˆäº¤é‡</th><th>è¶¨å‹¢</th>" "</tr></thead><tbody>")
    for idx, row in df_qv.iterrows():
        simple_param = "1" if simple_mode else "0"
        html += (f"<tr>"  
                    f"<td><a href='/chart/{row['stock_id']}?simple_mode={simple_param}&num_rows={num_rows}&list={list_param}&index={idx}&frequency={frequency}'>{row['stock_id']}</a></td>"  
                    f"<td>{row['stock_name']}</td>"  
                    f"<td>{int(row['latest_volume'])}</td>"  
                    f"<td>{row['adr14']:.2f}</td>"  
                    f"<td>{int(row['avg_volume_14'])}</td>"  
                    f"<td>{row['trend']}</td>"  
                    f"</tr>")
    html += "</tbody></table><br><a href='/'>è¿”å›</a>"
    return html

@app.route('/favorite', methods=['POST'])
def favorite_toggle():
    stock_id = request.form.get('stock_id', '').strip(); stock_name = request.form.get('stock_name', '').strip()
    # ğŸŒŸ ä¿®æ­£ï¼šå¦‚æœ stock_name æ˜¯ç©ºçš„ï¼Œä½¿ç”¨ stock_id ä½œç‚ºå‚™ç”¨åç¨±
    if not stock_name: stock_name = stock_id
    
    if not stock_id: return jsonify({"message": "è‚¡ç¥¨ä»£è™Ÿä¸å¯ç‚ºç©º"}), 400
    
    try:
        # 1. æª¢æŸ¥æ˜¯å¦å­˜åœ¨
        res_check = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params={"stock_id": f"eq.{stock_id}", "select": "stock_id"}); res_check.raise_for_status(); exists = len(res_check.json()) > 0
    except Exception as e: return jsonify({"message": f"æª¢æŸ¥æœ€æ„›å¤±æ•—: {e}"}), 500

    try:
        if exists:
            # 2. å­˜åœ¨å‰‡åŸ·è¡Œ DELETE (ç§»é™¤)
            res = requests.delete(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params={"stock_id": f"eq.{stock_id}"}); res.raise_for_status()
            return jsonify({"message": f"{stock_name} ({stock_id}) å·²å¾æœ€æ„›ç§»é™¤", "favorite": False})
        else:
            # 3. ä¸å­˜åœ¨å‰‡åŸ·è¡Œ POST (æ–°å¢)
            payload = {"stock_id": stock_id, "stock_name": stock_name}
            # ä½¿ç”¨ json=payload å’Œæ­£ç¢ºçš„ Content-Type æ¨™é ­
            res = requests.post(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers={**headers, "Content-Type": "application/json"}, json=payload); res.raise_for_status()
            return jsonify({"message": f"{stock_name} ({stock_id}) å·²åŠ å…¥æœ€æ„›", "favorite": True})
    except Exception as e: return jsonify({"message": f"æ“ä½œæœ€æ„›å¤±æ•—: {e}"}), 500

@app.route('/favorites_clear', methods=['POST'])
def favorites_clear():
    try:
        # ä½¿ç”¨ neq.null æ¢ä»¶åˆªé™¤æ‰€æœ‰è¨˜éŒ„
        res = requests.delete(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params={"stock_id": "neq.null"})  
        res.raise_for_status(); return "<script>alert('å·²åˆªé™¤æ‰€æœ‰æœ€æ„›è‚¡ç¥¨'); window.location.href='/'</script>"
    except Exception as e: return f"<h2>åˆªé™¤æœ€æ„›å¤±æ•—: {e}</h2><a href='/'>è¿”å›é¦–é </a>"

# ----------------- é‹è¡Œç¨‹å¼ -----------------
if __name__ == '__main__':
    # ... (æ‚¨çš„é‹è¡Œä»£ç¢¼) ...
    pass

# ----------------- é‹è¡Œæ‡‰ç”¨ç¨‹å¼ -----------------
if __name__ == '__main__':
    # åƒ…åœ¨æœ¬æ©Ÿé–‹ç™¼ç’°å¢ƒä½¿ç”¨ï¼Œå¯¦éš›éƒ¨ç½²è«‹ä½¿ç”¨ WSGI æœå‹™å™¨
    app.run(debug=True, host='0.0.0.0', port=5000)