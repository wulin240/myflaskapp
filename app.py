from flask import Flask, render_template, request, jsonify
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import urllib.parse
from datetime import datetime, timedelta
import os
import json # ç¢ºä¿å¯ä»¥è™•ç† JSON éŸ¿æ‡‰

app = Flask(__name__)

# ----------------- Supabase è¨­å®š -----------------
# è«‹å°‡é€™è£¡æ›¿æ›æˆæ‚¨çš„ Supabase å°ˆæ¡ˆè³‡è¨Š
SUPABASE_URL = "https://djhdpltrhlhqfxmwniki.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImRqaGRwbHRyaGxocWZ4bXduaWtpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjMwNjQwODgsImV4cCI6MjA3ODY0MDA4OH0.jwSPe-HMHxv2xGCjS42O5Cjby0KtgsHEStlQWs0cyPk"
TABLE_NAME = "stock_data"
FAVORITE_TABLE = "favorites"
QUICK_VIEW_TABLE = "quick_view"  # ç¢ºä¿é€™è¡Œåœ¨é€™è£¡å®šç¾©

headers = {
    "apikey": SUPABASE_KEY.strip(),
    "Authorization": f"Bearer {SUPABASE_KEY.strip()}",
    "Content-Type": "application/json" # æ–°å¢ Content-Type ç¢ºä¿ POST/DELETE æ­£ç¢º
}

# ----------------- è¼”åŠ©å‡½æ•¸ï¼šæœ€æ„›è‚¡ç¥¨æª¢æŸ¥ -----------------
def is_favorite(stock_id):
    """æª¢æŸ¥è‚¡ç¥¨æ˜¯å¦å·²åŠ å…¥æœ€æ„›"""
    try:
        # ä½¿ç”¨ count æŸ¥è©¢ä¾†å„ªåŒ–æ€§èƒ½
        params = {"stock_id": f"eq.{stock_id}", "select": "count"}
        res = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params=params, timeout=10)
        res.raise_for_status()
        # Supabase count å›æ‡‰æœƒåœ¨ Headers ä¸­çš„ Content-Range
        return int(res.headers.get("Content-Range").split('/')[-1]) > 0
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥æœ€æ„›å¤±æ•—: {e}")
        return False
        
# ----------------- æŠ“å–è‚¡ç¥¨è³‡æ–™ -----------------
def fetch_stock_data(stock_id):
    """å¾ Supabase ç²å–è‚¡ç¥¨ OHLCV æ•¸æ“š"""
    stock_id_clean = stock_id.replace(".TW","").replace(".TWO","")
    params = {"stock_id": f"eq.{stock_id_clean}", "order": "date.asc", "select": "*, stock_name"}

    try:
        res = requests.get(
            f"{SUPABASE_URL}/rest/v1/{TABLE_NAME}", headers=headers, params=params, timeout=30
        )
        res.raise_for_status()
        data = res.json()
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data)
        df['date'] = pd.to_datetime(df['date'])
        return df
    except Exception as e:
        print(f"âš ï¸ Supabase è®€å– {stock_id} å¤±æ•—: {e}")
        return pd.DataFrame()

# ----------------- æ•¸æ“šè™•ç†æ ¸å¿ƒåŠŸèƒ½ -----------------

def convert_to_weekly(df_daily):
    """å°‡æ—¥ç·šæ•¸æ“š (OHLCV) è½‰æ›ç‚ºé€±ç·šæ•¸æ“šã€‚"""
    if df_daily.empty: return df_daily
    df = df_daily.set_index('date')
    weekly_data = df.resample('W').agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    })
    df_weekly = weekly_data.dropna(subset=['open']).reset_index()
    if not df_daily.empty and 'stock_name' in df_daily.columns:
        df_weekly['stock_name'] = df_daily['stock_name'].iloc[-1]
    if not df_daily.empty and 'stock_id' in df_daily.columns:
        df_weekly['stock_id'] = df_daily['stock_id'].iloc[-1]
    return df_weekly


def kline_merge(df):
    """Kç·šåˆä½µï¼šæ¡ç”¨æ›´ç©©å¥çš„åŒ…å«é—œä¿‚åˆ¤å®šé‚è¼¯ï¼Œè™•ç†é‚Šç•Œæƒ…æ³ã€‚ï¼ˆçºè«–ç­†æ®µé è™•ç†ï¼‰"""
    if df.empty: return df
    df_raw = df.copy().set_index('date')
    processed_kline = []
    
    current_kline = {col: df_raw.iloc[0][col] for col in ['open', 'high', 'low', 'close', 'volume']}
    current_kline['Index'] = df_raw.index[0]

    for i in range(1, len(df_raw)):
        next_row = df_raw.iloc[i]
        next_kline = {col: next_row[col] for col in ['open', 'high', 'low', 'close', 'volume']}
        
        # åŒ…å«é—œä¿‚åˆ¤å®šï¼šå¾Œä¸€æ ¹ K ç·šå®Œå…¨è¢«å‰ä¸€æ ¹ K ç·šåŒ…å«ï¼Œæˆ–å¾Œä¸€æ ¹ K ç·šå®Œå…¨åŒ…å«å‰ä¸€æ ¹ K ç·š
        is_inclusion = (
            (next_row['high'] <= current_kline['high'] and next_row['low'] >= current_kline['low']) or
            (next_row['high'] >= current_kline['high'] and next_row['low'] <= current_kline['low'])
        )
        
        if is_inclusion:
            current_kline['high'] = max(current_kline['high'], next_row['high'])
            current_kline['low'] = min(current_kline['low'], next_row['low'])
            current_kline['volume'] += next_row['volume']
            # ä¿ç•™æ–¹å‘ï¼šå¦‚æœæ˜¯åŒæ–¹å‘ï¼ˆä¾‹å¦‚éƒ½æ˜¯é™½ç·šï¼‰å‰‡å–æœ€æ–°æ”¶ç›¤åƒ¹ï¼Œä½†é€™è£¡ç°¡åŒ–ç‚ºåªå–æœ€æ–°æ”¶ç›¤åƒ¹
            current_kline['close'] = next_row['close']
            current_kline['Index'] = df_raw.index[i]
        else:
            processed_kline.append(current_kline)
            # å»ºç«‹æ–°çš„ K ç·šæ®µ
            current_kline = next_kline
            current_kline['Index'] = df_raw.index[i]
            
    processed_kline.append(current_kline)
    
    df_merged = pd.DataFrame(processed_kline).set_index('Index').rename_axis('date').reset_index()
    df_merged['date'] = pd.to_datetime(df_merged['date'])
    return df_merged


def find_divergence(df_merged):
    """åŸºç¤åˆ†å‹åˆ¤æ–·ï¼šä¸­é–“ K ç·šé«˜ä½é»å¤§æ–¼æˆ–ç­‰æ–¼å…©å´ã€‚"""
    df = df_merged.copy()
    df['H_prev'], df['H_next'] = df['high'].shift(1), df['high'].shift(-1)
    df['L_prev'], df['L_next'] = df['low'].shift(1), df['low'].shift(-1)
    # é ‚åˆ†å‹ï¼šä¸­é–“ high >= å·¦å³ high
    df['Is_Top_Divergence'] = (df['high'] >= df['H_prev']) & (df['high'] >= df['H_next'])
    # åº•åˆ†å‹ï¼šä¸­é–“ low <= å·¦å³ low
    df['Is_Bottom_Divergence'] = (df['low'] <= df['L_prev']) & (df['low'] <= df['L_next'])
    df['Is_Top_Divergence'] = df['Is_Top_Divergence'].fillna(False)
    df['Is_Bottom_Divergence'] = df['Is_Bottom_Divergence'].fillna(False)
    df['Top_Price'] = np.where(df['Is_Top_Divergence'], df['high'], np.nan)
    df['Bottom_Price'] = np.where(df['Is_Bottom_Divergence'], df['low'], np.nan)
    return df


def find_stroke_pivots(df_merged):
    """
    ğŸŒŸ åš´æ ¼ç­†æ®µåˆ¤æ–·å‡½æ•¸ã€‚ç¯©é¸å‡ºç¬¦åˆã€Œå…©åˆ†å‹ä¹‹é–“è‡³å°‘æœ‰ä¸€æ ¹éåŒ…å« K ç·šã€çš„è½‰æŠ˜é»ã€‚
    """
    df_divergence = find_divergence(df_merged.copy())
    pivot_points = df_divergence[df_divergence['Is_Top_Divergence'] | df_divergence['Is_Bottom_Divergence']].copy()

    if pivot_points.empty: return pd.DataFrame()

    # 1: é ‚åˆ†å‹, -1: åº•åˆ†å‹
    pivot_points['Type'] = np.where(pivot_points['Is_Top_Divergence'], 1, -1)
    
    final_pivots_list = []
    last_pivot_index = -1 # ç”¨ä¾†è¨˜éŒ„åœ¨ df_merged ä¸­çš„ç´¢å¼•ä½ç½®

    for idx, row in pivot_points.iterrows():
        # ç²å–ç•¶å‰åˆ†å‹åœ¨ df_merged ä¸­çš„å¯¦éš›ä½ç½®
        current_index_loc = df_merged[df_merged['date'] == row['date']].index[0]
        
        if not final_pivots_list:
            # ç¬¬ä¸€å€‹åˆ†å‹ç›´æ¥åŠ å…¥
            row['Pivot_Price_Calc'] = row['Top_Price'] if row['Type'] == 1 else row['Bottom_Price']
            final_pivots_list.append(row)
            last_pivot_index = current_index_loc
            continue
            
        last_pivot = final_pivots_list[-1]
        last_pivot_index_loc = df_merged[df_merged['date'] == last_pivot['date']].index[0]
        
        if row['Type'] == last_pivot['Type']:
            # åŒå‘åˆ†å‹ï¼Œæ ¹æ“šåƒ¹æ ¼å–æ¥µå€¼ï¼Œä¸¦æ›¿æ›æ‰å‰ä¸€å€‹åˆ†å‹
            is_new_extreme = (row['Type'] == 1 and row['Top_Price'] > last_pivot['Top_Price']) or \
                             (row['Type'] == -1 and row['Bottom_Price'] < last_pivot['Bottom_Price'])
            
            if is_new_extreme:
                # æ›´æ–°å‰ä¸€å€‹åˆ†å‹ï¼ˆæ›¿æ›ï¼‰
                # æ³¨æ„ï¼šé€™è£¡æ‡‰è©²æ›´æ–° final_pivots_list è£¡æœ€å¾Œä¸€é …çš„æ•¸æ“šï¼Œè€Œä¸æ˜¯ last_pivot
                final_pivots_list[-1].update({'date': row['date'],
                                              'Top_Price': row['Top_Price'] if row['Type'] == 1 else last_pivot['Top_Price'],
                                              'Bottom_Price': row['Bottom_Price'] if row['Type'] == -1 else last_pivot['Bottom_Price'],
                                              'Pivot_Price_Calc': row['Top_Price'] if row['Type'] == 1 else row['Bottom_Price'],
                                              'Is_Top_Divergence': row['Is_Top_Divergence'],
                                              'Is_Bottom_Divergence': row['Is_Bottom_Divergence']})
                last_pivot_index = current_index_loc
        else:
            # ç•°å‘åˆ†å‹ï¼šæª¢æŸ¥æ˜¯å¦æ»¿è¶³åš´æ ¼ç­†æ®µå®šç¾© (è‡³å°‘é–“éš”ä¸€æ ¹ K ç·šï¼Œå³ index è·é›¢ >= 2)
            kline_count_between = current_index_loc - last_pivot_index_loc
            if kline_count_between >= 2:
                row['Pivot_Price_Calc'] = row['Top_Price'] if row['Type'] == 1 else row['Bottom_Price']
                final_pivots_list.append(row)
                last_pivot_index = current_index_loc
                
    # ç”±æ–¼ last_pivot åœ¨å¾ªç’°ä¸­æ›´æ–°çš„æ˜¯å­—å…¸å¼•ç”¨ï¼Œæˆ‘å€‘éœ€è¦é‡æ–°æ§‹é€  DataFrame ä»¥ç¢ºä¿æ•¸æ“šæ­£ç¢º
    df_filtered = pd.DataFrame(final_pivots_list)

    if df_filtered.empty: return pd.DataFrame()
        
    df_filtered['date'] = pd.to_datetime(df_filtered['date'])
    df_pivot_data = df_filtered[['date', 'Type', 'Pivot_Price_Calc']].rename(columns={
        'Type': 'Pivot_Type',
        'Pivot_Price_Calc': 'Pivot_Price'
    })
    return df_pivot_data


def filter_pivots_for_stroke(df_result, df_original):
    """å°‡åˆ†å‹çµæœåˆä½µå›åŸå§‹Kç·šæ•¸æ“šï¼Œä¸¦æ‰¾å‡ºæœ€å¾Œä¸€å€‹è½‰æŠ˜é»çš„è³‡è¨Šã€‚"""
    df_original['date'] = pd.to_datetime(df_original['date'])
    
    # è™•ç†ç„¡è½‰æŠ˜é»çš„æƒ…æ³
    if df_result.empty:
        df_original['Pivot_Type'] = 0
        df_original['Pivot_Price'] = np.nan
        return df_original, None, 0

    last_pivot_row = df_result.iloc[-1]
    last_date = last_pivot_row['date']
    last_type = last_pivot_row['Pivot_Type']
    
    df_merged = df_original.merge(df_result, on='date', how='left')
    df_merged['Pivot_Type'] = df_merged['Pivot_Type'].fillna(0).astype(int)
    df_merged['Pivot_Price'] = df_merged['Pivot_Price'].fillna(np.nan)
    
    return df_merged, last_date, last_type


def analyze_trend_by_pivots(pivot_df):
    """åŸºæ–¼æœ‰æ•ˆè½‰æŠ˜é»åˆ¤æ–·é ‚åº•è¶¨å‹¢ (HH/HL)"""
    if pivot_df.empty or len(pivot_df) < 4:
        return {'Overall_Trend': "çµæ§‹æ•¸æ“šä¸è¶³ (éœ€è‡³å°‘å››å€‹æœ‰æ•ˆè½‰æŠ˜é»)"}

    # ç¢ºä¿åªä½¿ç”¨æœ€æ–°çš„ã€æœ‰æ•ˆçš„é ‚é»å’Œåº•é»
    tops = pivot_df[pivot_df['Pivot_Type'] == 1]['Pivot_Price'].dropna()
    bottoms = pivot_df[pivot_df['Pivot_Type'] == -1]['Pivot_Price'].dropna()

    if len(tops) < 2 or len(bottoms) < 2:
        return {'Overall_Trend': "çµæ§‹æ•¸æ“šä¸è¶³ (éœ€è‡³å°‘å…©å€‹é ‚é»å’Œå…©å€‹åº•é»)"}

    # å–æœ€è¿‘çš„å…©å€‹é ‚é» (T2, T1) å’Œå…©å€‹åº•é» (B2, B1)
    # T2/B2 æ˜¯æœ€æ–°çš„
    T2, T1 = tops.iloc[-1], tops.iloc[-2]
    B2, B1 = bottoms.iloc[-1], bottoms.iloc[-2]

    is_hh, is_hl = T2 > T1, B2 > B1 # Higher High, Higher Low
    is_lh, is_ll = T2 < T1, B2 < B1 # Lower High, Lower Low

    trend_result = "ç›¤æ•´/å¾…ç¢ºèª"
    if is_hh and is_hl: trend_result = "âœ… ä¸Šå‡è¶¨å‹¢ (Higher Highs & Higher Lows)"
    elif is_lh and is_ll: trend_result = "ğŸ”» ä¸‹é™è¶¨å‹¢ (Lower Highs & Lower Lows)"
    elif is_hh and is_ll: trend_result = "âš ï¸ æ“´å¼µçµæ§‹ (é«˜é»æŠ¬é«˜, ä½é»é™ä½)"
    elif is_lh and is_hl: trend_result = "â³ æ”¶æ–‚çµæ§‹ (é«˜é»é™ä½, ä½é»æŠ¬é«˜)"
        
    return {'Overall_Trend': trend_result}

def check_rebound_signal(df_full_processed, trend_period=90):
    """çµæ§‹å›èª¿èµ·æ¼²ä¿¡è™Ÿæª¢æŸ¥ (ä¸»è¦ç”¨æ–¼åˆ¤æ–·å¤šé ­å›èª¿æ˜¯å¦å‡ºç¾è²·é»)"""
    if len(df_full_processed) < trend_period + 5:
        return False, "æ•¸æ“šä¸è¶³ä»¥åˆ¤æ–·é•·ç·šè¶¨å‹¢"

    df_check = df_full_processed.iloc[-trend_period:].copy()
    pivot_df = df_check[df_check['Pivot_Type'] != 0].copy()
    current = df_check.iloc[-1]
    prev = df_check.iloc[-2]

    trend_result = analyze_trend_by_pivots(pivot_df)['Overall_Trend']
    is_high_level_trend = ('ä¸Šå‡è¶¨å‹¢' in trend_result)
    # é¡å¤– MA éæ¿¾æ¢ä»¶ï¼š60æ—¥å‡ç·šå‘ä¸Šä¸”æ”¶ç›¤åƒ¹åœ¨ 60 æ—¥å‡ç·šä¹‹ä¸Š
    is_ma_aligned = (df_check['MA60'].iloc[-1] > df_check['MA60'].iloc[0]) and (current['close'] > current['MA60'])
    
    if not (is_high_level_trend and is_ma_aligned):
        return False, f"âŒ é•·ç·šè¶¨å‹¢ä¸ç¬¦åˆ HH/HL ä¸Šå‡çµæ§‹æˆ– MA60 æ¢ä»¶ ({trend_result})"

    bottoms = pivot_df[pivot_df['Pivot_Type'] == -1]['Pivot_Price'].dropna()
    tops = pivot_df[pivot_df['Pivot_Type'] == 1]['Pivot_Price'].dropna()
    
    if len(bottoms) < 2 or len(tops) < 1:
        return False, "çµæ§‹è½‰æŠ˜é»ä¸è¶³ï¼Œç„¡æ³•å®šä½å›èª¿å€é–“"

    T_last = tops.iloc[-1]      # æœ€æ–°é«˜é»
    B_pre_T = bottoms.iloc[-2]  # å‰ä¸€å€‹ä½é» (å‰ä¸€å€‹ç­†æ®µçš„åº•éƒ¨æ”¯æ’)
    
    # æ­£åœ¨å›èª¿ä¸­ (åƒ¹æ ¼å¾é«˜é»ä¸‹ä¾†)
    is_correcting = (current['close'] < T_last)
    # å®ˆä½å‰ä¸€å€‹ä½é» (B_pre_T) çš„æ”¯æ’
    is_holding_support = (current['low'] > B_pre_T)
    
    if not (is_correcting and is_holding_support):
        if current['close'] > T_last:
            return False, "âœ… å·²ç¶“çªç ´å‰é«˜ï¼Œå›èª¿å·²çµæŸï¼Œå±¬æ–¼æ–°çš„ä¸Šæ¼²æ³¢æ®µ"
        return False, f"ğŸš¨ çµæ§‹æ€§å›èª¿å¤±æ•—ï¼šä½é»å·²è·Œç ´çµæ§‹æ”¯æ’ B_pre_T ({B_pre_T:.2f})"

    # æª¢æŸ¥ K ç·šç¢ºèªè¨Šè™Ÿï¼šçœ‹æ¼²åå™¬ (Bullish Engulfing)
    is_bullish_engulfing = (
        (current['close'] > current['open']) and  # ç•¶å¤©æ˜¯é™½ç·š
        (current['close'] > prev['open']) and  # ç•¶å¤©æ”¶ç›¤åƒ¹é«˜æ–¼å‰ä¸€å¤©é–‹ç›¤åƒ¹
        (current['open'] < prev['close'])     # ç•¶å¤©é–‹ç›¤åƒ¹ä½æ–¼å‰ä¸€å¤©æ”¶ç›¤åƒ¹
    )
    # æª¢æŸ¥ K ç·šç¢ºèªè¨Šè™Ÿï¼šæ”¶ç›¤ç«™ä¸Š MA20 ä¸”çªç ´å‰ä¸€æ ¹ K ç·šé«˜é»æˆ–å½¢æˆçœ‹æ¼²åå™¬
    is_rebound_confirmed = (
        current['close'] > current['MA20']
        and (current['close'] > prev['high'] or is_bullish_engulfing)
    )

    if is_rebound_confirmed:
        return True, f"âœ… **ã€çµæ§‹å›èª¿èµ·æ¼²ä¿¡è™Ÿã€‘**ï¼šåƒ¹æ ¼åœ¨ B_pre_T æ”¯æ’ä¸Šç¢ºèªåè½‰ï¼(æ”¯æ’ä½: {B_pre_T:.2f})"
    else:
        return False, f"ğŸ’¡ **æ½›åœ¨èµ·æ¼²æç¤º**ï¼šçµæ§‹å·²ç¢ºèªç‚ºå¥åº·å›èª¿å€é–“ ({B_pre_T:.2f} æ”¯æ’), ç­‰å¾…å¼·å‹¢ K ç·šç¢ºèªèµ·æ¼²ï¼"


import pandas as pd
import numpy as np

# ----------------- ğŸŒŸ NEW: ä¸»åŠ›è¡Œç‚ºåµæ¸¬æ ¸å¿ƒå‡½æ•¸ -----------------
# ----------------- ğŸŒŸ I. ä¸»åŠ›è¡Œç‚ºåµæ¸¬æ ¸å¿ƒå‡½æ•¸ (æœ€çµ‚ä¿®å¾©ç‰ˆ - å« RSI èƒŒé›¢) -----------------
import pandas as pd
import numpy as np

def detect_smart_money_signals(df_input, vsa_vol_multiplier=2, rsi_period=14):
    """
    ä¸»åŠ›è¡Œç‚ºåµæ¸¬ - åˆ¤æ–·æ½›åœ¨çš„ä¸»åŠ›æ‹‰æŠ¬å’Œæ‹‹å”®è¨Šè™Ÿï¼Œä¸¦åŒ…å« RSI èƒŒé›¢åµæ¸¬ã€‚
    å‰æï¼šå‚³å…¥çš„ df_input å¿…é ˆå·²åŒ…å« MA20, MA60, BB_UP/LOW, ATR14 ç­‰æ‰€æœ‰åŸºç¤æŒ‡æ¨™ã€‚
    """
    
    df = df_input.copy()
    
    # ğŸŒŸ ä¿®æ­£é»ï¼šç¢ºä¿ç´¢å¼•é€£çºŒä¸”æ—¥æœŸæ¬„ä½å­˜åœ¨
    if 'date' not in df.columns:
        df.reset_index(inplace=True) 
    df.reset_index(drop=True, inplace=True) # ç¢ºä¿ç´¢å¼•æ˜¯ 0, 1, 2, ...
    
    # --- åŸºç¤æŒ‡æ¨™è¨ˆç®— (VWAP, RSI) ---
    df['TP'] = (df['high'] + df['low'] + df['close']) / 3
    df['VOL20'] = df['volume'].rolling(20).mean()
    
    # K ç·šå¯¦é«”ä¸Šä¸‹é™ (ç”¨æ–¼è¤‡åˆè¨Šè™Ÿ)
    df['Body_Max'] = df[['open', 'close']].max(axis=1)
    df['Body_Min'] = df[['open', 'close']].min(axis=1)
    
    # VWAP ç´¯ç©è¨ˆç®— (é‡å°å‚³å…¥çš„æ•¸æ“šç¯„åœ)
    df['TPV'] = df['TP'] * df['volume']
    df['VWAP'] = df['TPV'].cumsum() / df['volume'].cumsum()
    
    # RSI (ä¿æŒèˆ‡èˆŠç‰ˆç›¸åŒè¨ˆç®—æ–¹æ³•)
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    # ä½¿ç”¨ 14 æœŸ RSI
    avg_gain = gain.ewm(com=rsi_period - 1, adjust=False).mean()
    avg_loss = loss.ewm(com=rsi_period - 1, adjust=False).mean()
    rs = avg_gain / avg_loss.replace(0, 1e-9)
    df['RSI'] = 100 - (100 / (1 + rs))

    # K ç·šå½¢æ…‹èˆ‡é‡èƒ½
    df['Body_Ratio'] = (df['close'] - df['open']).abs() / (df['high'] - df['low']).replace(0, 1e-6)
    is_high_volume = df['volume'] >= (df['VOL20'] * vsa_vol_multiplier)
    is_long_bull_k = (df['close'] > df['open']) & (df['Body_Ratio'] > 0.6)
    is_long_bear_k = (df['close'] < df['open']) & (df['Body_Ratio'] > 0.6)
    
    # --- 1. VSA å¼·å‹¢æ‹‰æŠ¬ (å¸ç±Œ) --- 
    df['Signal_VSA_Strong'] = np.where(is_long_bull_k & is_high_volume, df['low'] * 0.99, np.nan)
    
    # --- 2. ä¸»åŠ›æˆæœ¬çªç ´è¨Šè™Ÿï¼šæ”¶ç›¤ç«™ä¸Š VWAP --- 
    df['Signal_VWAP_Break'] = np.where(
        (df['close'] > df['VWAP']) & (df['close'].shift(1).fillna(-np.inf) <= df['VWAP'].shift(1).fillna(-np.inf)),
        df['low'] * 0.995,
        np.nan
    )
    
    # --- 3. è¤‡åˆå‹ä¸»åŠ›å¸ç±Œçªç ´ (Accumulation Breakout) (ä¿ç•™æ–°ç‰ˆé‚è¼¯) --- 
    is_ma20_gt_ma60 = df['MA20'] > df['MA60']
    is_low_gt_ma20 = df['low'] > df['MA20']
    
    is_near_ma20 = (df['low'] < df['MA20'] * 1.10) & (df['low'] > df['MA20'] * 0.90)
    ma20_max = df['MA20'].rolling(20).max()
    ma20_min = df['MA20'].rolling(20).min()
    ma20_min_safe = ma20_min.replace(0, 1e-6)
    is_ma20_flat = (ma20_max / ma20_min_safe) < 1.10
    highest_close_20d = df['close'].shift(1).rolling(20).max() 
    is_breaking_out = df['close'] > highest_close_20d
    
    is_body_contains_bb_up = (df['Body_Max'] >= df['BB_UP']) & (df['Body_Min'] < df['BB_UP'])
    is_not_overbought = df['close'] <= df['BB_UP']
    is_price_valid = is_near_ma20 | (is_not_overbought & is_body_contains_bb_up)
    
    condition_1_original = (is_near_ma20 & is_ma20_flat & is_breaking_out & is_high_volume & is_long_bull_k)
    condition_2_vsa_priority = (df['Signal_VSA_Strong'].notna() & is_price_valid & is_ma20_gt_ma60 & is_low_gt_ma20 & is_breaking_out & is_high_volume & is_long_bull_k)

    is_accumulation_breakout = condition_1_original | condition_2_vsa_priority
    
    df['Signal_Accumulation_Breakout'] = np.where(is_accumulation_breakout, df['low'] * 0.985, np.nan)
    
    # --- 4. VSA ææ…Œæ‹‹å”® (æ´¾ç™¼/å‡ºè²¨) ---
    df['Signal_VSA_Weak'] = np.where(is_long_bear_k & is_high_volume, df['high'] * 1.01, np.nan)

    # --- 5. ä¸»åŠ›æˆæœ¬è·Œç ´è¨Šè™Ÿï¼šæ”¶ç›¤è·Œç ´ VWAP ---
    df['Signal_VWAP_BreakDown'] = np.where(
        (df['close'] < df['VWAP']) & (df['close'].shift(1).fillna(np.inf) >= df['VWAP'].shift(1).fillna(np.inf)),
        df['high'] * 1.005, 
        np.nan
    )
    
    # ----------------------------------------------------
    # --- 6. ğŸŒŸ æ•´åˆ RSI èƒŒé›¢è¨Šè™Ÿ (ä½¿ç”¨èˆŠç‰ˆé‚è¼¯) ---
    # ----------------------------------------------------
    divergence_signal = [np.nan] * len(df)
    top_divergence_signal = [np.nan] * len(df)
    
    # æ‰¾å‡ºåº•åˆ†å‹å’Œé ‚åˆ†å‹ (3æ ¹Kç·šåˆ¤æ–·ï¼Œèˆ‡èˆŠç‰ˆç›¸åŒ)
    # é€™è£¡ä½¿ç”¨ df.index ç¢ºä¿åŸºæ–¼ 0 é–‹å§‹çš„é€£çºŒç´¢å¼•é€²è¡Œ loc è¨ªå•
    df['Temp_Bottom_Pivot'] = (df['low'].shift(-1) > df['low']) & (df['low'].shift(1) > df['low'])
    df['Temp_Top_Pivot'] = (df['high'].shift(-1) < df['high']) & (df['high'].shift(1) < df['high'])
    
    # ç¢ºä¿åªè€ƒæ…®ç•¶å‰ç¯„åœå…§çš„è½‰æŠ˜é»
    bottom_pivots = df[df['Temp_Bottom_Pivot']].copy()
    top_pivots = df[df['Temp_Top_Pivot']].copy()

    # --- åº•éƒ¨èƒŒé›¢ (Signal_Divergence) ---
    if len(bottom_pivots) >= 2:
        for i in range(1, len(bottom_pivots)):
            B2_idx = bottom_pivots.index[i]
            B1_idx = bottom_pivots.index[i-1]
            
            # åƒ¹æ ¼åº•åº•ä½ (Price Lower Low): B2 low < B1 low
            is_price_ll = df.loc[B2_idx, 'low'] < df.loc[B1_idx, 'low']
            # RSI åº•åº•é«˜ (RSI Higher Low): B2 RSI > B1 RSI
            is_rsi_hh = df.loc[B2_idx, 'RSI'] > df.loc[B1_idx, 'RSI']

            if is_price_ll and is_rsi_hh:
                divergence_signal[B2_idx] = df.loc[B2_idx, 'low'] * 0.998 # æ¨™è¨˜åœ¨ K ç·šåº•éƒ¨é™„è¿‘

    # --- é ‚éƒ¨èƒŒé›¢ (Signal_TopDivergence) ---
    if len(top_pivots) >= 2:
        for i in range(1, len(top_pivots)):
            T2_idx = top_pivots.index[i]
            T1_idx = top_pivots.index[i-1]
            
            # åƒ¹æ ¼é ‚é ‚é«˜ (Price Higher High): T2 high > T1 high
            is_price_hh = df.loc[T2_idx, 'high'] > df.loc[T1_idx, 'high']
            # RSI é ‚é ‚ä½ (RSI Lower High): T2 RSI < T1 RSI
            is_rsi_ll = df.loc[T2_idx, 'RSI'] < df.loc[T1_idx, 'RSI']

            if is_price_hh and is_rsi_ll:
                top_divergence_signal[T2_idx] = df.loc[T2_idx, 'high'] * 1.002 # æ¨™è¨˜åœ¨ K ç·šé ‚éƒ¨é™„è¿‘
    
    # å°‡åˆ—è¡¨è½‰æ›ç‚º Series ä¸¦è³¦å€¼
    df['Signal_Divergence'] = pd.Series(divergence_signal, index=df.index)
    df['Signal_TopDivergence'] = pd.Series(top_divergence_signal, index=df.index)
    
    # ----------------------------------------------------
    # --- è¨Šè™Ÿå„ªå…ˆç´šæ¸…ç† (ä¿ç•™æ–°ç‰ˆè¤‡åˆè¨Šè™Ÿçš„è™•ç†) ---
    # ----------------------------------------------------
    
    # å°‡è¤‡åˆè¨Šè™Ÿä¹Ÿç´å…¥å¼·å‹¢è²·å…¥
    is_any_strong_buy = df['Signal_VSA_Strong'].notna() | df['Signal_VWAP_Break'].notna() | df['Signal_Accumulation_Breakout'].notna()
    is_any_strong_sell = df['Signal_VSA_Weak'].notna() | df['Signal_VWAP_BreakDown'].notna()

    # 1. è²·å…¥è¨Šè™Ÿå„ªå…ˆï¼šå¼·å‹¢è²·å…¥æ—¥æ¸…é™¤æ‰€æœ‰çœ‹è·Œ/è³£å‡ºè¨Šè™Ÿ (åŒ…å«é ‚èƒŒé›¢)
    df.loc[is_any_strong_buy, ['Signal_VSA_Weak', 'Signal_VWAP_BreakDown', 'Signal_TopDivergence']] = np.nan
    
    # 2. è³£å‡ºè¨Šè™Ÿå„ªå…ˆï¼šå¼·å‹¢è³£å‡ºæ—¥æ¸…é™¤æ‰€æœ‰çœ‹æ¼²/è²·å…¥è¨Šè™Ÿ (åŒ…å«åº•èƒŒé›¢å’Œè¤‡åˆè¨Šè™Ÿ)
    df.loc[is_any_strong_sell, ['Signal_VSA_Strong', 'Signal_VWAP_Break', 'Signal_Accumulation_Breakout', 'Signal_Divergence']] = np.nan
    
    # æœ€çµ‚å›å‚³æ‰€æœ‰è¨Šè™Ÿæ¬„ä½ + å¿…è¦çš„æŒ‡æ¨™æ¬„ä½ (ATR14/BB_UP/BB_LOW)
    # ç¢ºä¿ BB_UP/BB_LOW/ATR14 è¢«è¿”å›ï¼Œä»¥ä¾¿åœ¨ generate_chart ä¸­è¨ˆç®—åç§»
    return df[['date', 
                'Signal_VSA_Strong', 'Signal_VWAP_Break', 'Signal_Divergence', 'Signal_Accumulation_Breakout',
                'Signal_VSA_Weak', 'Signal_VWAP_BreakDown', 'Signal_TopDivergence', 'BB_UP', 'BB_LOW', 'ATR14']]
# ----------------- æ•´åˆç”Ÿæˆåœ–è¡¨ (å«è¶¨å‹¢åˆ†æå’Œè¨Šè™Ÿæª¢æŸ¥) -----------------
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.signal import argrelextrema

# å‡è¨­ä»¥ä¸‹è¼”åŠ©å‡½æ•¸å·²å®šç¾©ä¸¦å¯ä½¿ç”¨ï¼š
# fetch_stock_data, convert_to_weekly, kline_merge, find_stroke_pivots, 
# filter_pivots_for_stroke, detect_smart_money_signals, analyze_trend_by_pivots, 
# check_rebound_signal 

import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
# å‡è¨­ argrelextrema ä¾†è‡ª scipy.signal
from scipy.signal import argrelextrema 
# å‡è¨­æ‰€æœ‰è¼”åŠ©å‡½æ•¸å·²åœ¨æ­¤è™•æˆ–å…¶ä»–æ–‡ä»¶ä¸­å°å…¥:
# from your_modules import fetch_stock_data, convert_to_weekly, kline_merge, find_stroke_pivots, filter_pivots_for_stroke, detect_smart_money_signals, analyze_trend_by_pivots, check_rebound_signal


def generate_chart(stock_id_clean, start_date=None, end_date=None, simple_mode=False, num_rows=30, frequency='D', n_sr_levels=3):
    """ç”ŸæˆåŒ…å« K ç·šåœ–ã€çºè«–ç­†æ®µã€æŠ€è¡“æŒ‡æ¨™å’Œä¸»åŠ›è¨Šè™Ÿçš„ Plotly åœ–è¡¨ã€‚
       - ä¿®æ­£ï¼šS/R çŸ©å½¢å¯¬åº¦ä½¿ç”¨ ATR åŸºç¤å‹•æ…‹èª¿æ•´ã€‚
    """
    
    # ğŸŒŸ è¨­å®š S/R çµ„æ•¸
    N_SR_LEVELS = int(n_sr_levels) if n_sr_levels else 3
    if N_SR_LEVELS < 1: N_SR_LEVELS = 1 
    
    # ğŸŒŸ ã€ATR å¯¬åº¦è¨­å®šã€‘
    # è¨­ç½®çŸ©å½¢å¯¬åº¦ç‚º ATR14 çš„ç™¾åˆ†æ¯”ã€‚0.8 ä»£è¡¨ S/R å€é–“å¯¬åº¦ = 0.8 * ATR14ã€‚
    ATR_MULTIPLIER = 0.2 
    
    # ç²å–è³‡æ–™
    df_original = fetch_stock_data(stock_id_clean)
    if df_original.empty: return None, f"{stock_id_clean} ç„¡è³‡æ–™", "N/A", "N/A", "neutral"

    df_full = df_original.copy()
    
    # è™•ç†é »ç‡å’Œæ—¥æœŸéæ¿¾
    if frequency == 'W': df_full = convert_to_weekly(df_full)
    
    if start_date and end_date:
        df_full = df_full[
            (df_full['date'] >= pd.to_datetime(start_date)) &
            (df_full['date'] <= pd.to_datetime(end_date))
        ]

    if df_full.empty: return None, f"{stock_id_clean} åœ¨ {start_date} ~ {end_date} ç„¡è³‡æ–™", "N/A", "N/A", "neutral"

    # --- 1. æŠ€è¡“æŒ‡æ¨™è¨ˆç®— (æ‰€æœ‰æŒ‡æ¨™é›†ä¸­æ–¼ df_tech) ---
    df_tech = df_full.copy()
    df_tech['TP'] = (df_tech['high'] + df_tech['low'] + df_tech['close']) / 3
    
    for ma in [5, 10, 20, 60]: df_tech[f"MA{ma}"] = df_tech['close'].rolling(ma).mean()
 
    df_tech['VOL5'] = df_tech['volume'].rolling(5).mean()
    df_tech['VOL20'] = df_tech['volume'].rolling(20).mean()
    
    df_tech['H-L'] = df_tech['high'] - df_tech['low']
    df_tech['H-PC'] = abs(df_tech['high'] - df_tech['close'].shift(1))
    df_tech['L-PC'] = abs(df_tech['low'] - df_tech['close'].shift(1))
    df_tech['TR'] = df_tech[['H-L', 'H-PC', 'L-PC']].max(axis=1)
    df_tech['ATR14'] = df_tech['TR'].rolling(14).mean().round(3)
    df_tech['stop_loss'] = df_tech['low'] - df_tech['ATR14'].fillna(0)
    
    df_tech['StdDev'] = df_tech['close'].rolling(20).std()
    df_tech['BB_UP'] = df_tech['MA20'] + (df_tech['StdDev'] * 2)
    df_tech['BB_LOW'] = df_tech['MA20'] - (df_tech['StdDev'] * 2)
    
    # --- 2. çºè«–ç­†æ®µè½‰æŠ˜é»è™•ç† ---
    df_merged = kline_merge(df_tech.copy())
    df_pivot_data = find_stroke_pivots(df_merged.copy())
    
    df_pivot_info, last_pivot_date, last_pivot_type = filter_pivots_for_stroke(df_pivot_data, df_tech.copy())

    df_final = df_tech.copy() 
    df_final = df_final.merge(
        df_pivot_info[['date', 'Pivot_Type', 'Pivot_Price']], 
        on='date', 
        how='left'
    )
    df_final['Pivot_Type'] = df_final['Pivot_Type'].fillna(0)
    df_final['Pivot_Price'] = df_final['Pivot_Price'].fillna(np.nan)
    
    # --- 3. ä¸»åŠ›ä¿¡è™Ÿåµæ¸¬ ---
    df_smart_signals = detect_smart_money_signals(df_final.copy(), vsa_vol_multiplier=2)
    
    final_signal_cols = [
        'date', 'Signal_VSA_Strong', 'Signal_VWAP_Break', 'Signal_Divergence', 
        'Signal_Accumulation_Breakout', 'Signal_VSA_Weak', 'Signal_VWAP_BreakDown', 
        'Signal_TopDivergence'
    ]
    df_final = df_final.merge(df_smart_signals[final_signal_cols], on='date', how='left')
    
    # --- 4. è¶¨å‹¢åˆ†æèˆ‡ä¿¡è™Ÿæª¢æŸ¥ ---
    df_display = df_final.tail(num_rows).copy()
    pivot_df_full = df_final[df_final['Pivot_Type'] != 0].copy()
    
    trend_analysis = analyze_trend_by_pivots(pivot_df_full)
    is_rebound, rebound_desc = check_rebound_signal(df_final)

    trend_desc_final = trend_analysis['Overall_Trend']
    
    trend_class = 'neutral'
    if 'ä¸‹é™è¶¨å‹¢' in trend_desc_final or 'ä¸‹ç©¿å‰åº•' in trend_desc_final:
        trend_class = 'bearish'
    elif 'ä¸Šå‡è¶¨å‹¢' in trend_desc_final or 'ä¸Šç©¿å‰é«˜' in trend_desc_final:
        trend_class = 'bullish'
        
    df_display['TPV_display'] = df_display['TP'] * df_display['volume']
    df_display['VWAP'] = df_display['TPV_display'].cumsum() / df_display['volume'].cumsum()
    
    # ----------------------------------------------------
    # ğŸŒŸ è¨ˆç®—åŸºæ–¼ ATR çš„åƒ¹æ ¼åŠå¯¬åº¦
    # ----------------------------------------------------
    if not df_display.empty and 'ATR14' in df_display.columns:
        last_atr = df_display['ATR14'].iloc[-1]
    else:
        # ç•¶è³‡æ–™ä¸è¶³æ™‚çš„å‚™ç”¨å¯¬åº¦ (ä¾‹å¦‚ 1 å…ƒ)
        last_atr = 1.0 
        
    # S/R çŸ©å½¢çš„çµ•å°åƒ¹æ ¼åŠå¯¬åº¦ = (ATR * ä¹˜æ•¸) / 2
    price_half_width = (last_atr * ATR_MULTIPLIER) / 2
    
    # ç¢ºä¿åŠå¯¬åº¦æœ‰æ„ç¾©
    if price_half_width <= 0.001: 
        price_half_width = 0.1 # è¨­å®šæœ€å°åŠå¯¬ 0.1 å…ƒ
    
    # --- 5. S/R åµæ¸¬é‚è¼¯ï¼šå°‹æ‰¾æœ€è¿‘çš„ N çµ„ ---
    order = 15 

    high_indices = argrelextrema(df_tech['high'].values, np.greater, order=order)[0]
    low_indices = argrelextrema(df_tech['low'].values, np.less, order=order)[0]

    all_resistance_levels = df_tech['high'].iloc[high_indices].tolist()
    all_support_levels = df_tech['low'].iloc[low_indices].tolist()

    current_price = df_display['close'].iloc[-1]
    
    # 1. ç¯©é¸å£“åŠ› (é«˜æ–¼ç¾åƒ¹) ä¸¦æŒ‰è·é›¢æ’åº
    closest_resistances = sorted([
        level for level in all_resistance_levels if level > current_price
    ], key=lambda x: x - current_price)[:N_SR_LEVELS]

    # 2. ç¯©é¸æ”¯æ’ (ä½æ–¼ç¾åƒ¹) ä¸¦æŒ‰è·é›¢æ’åº (å¾è¿‘åˆ°é )
    closest_supports = sorted([
        level for level in all_support_levels if level < current_price
    ], key=lambda x: current_price - x)[:N_SR_LEVELS]

    # 3. æº–å‚™ç¹ªè£½æ¸…å–® (åŒ…å« level å’Œ description)
    sr_levels_to_plot = []
    
    for i, level in enumerate(closest_resistances):
        res_percent = (level / current_price - 1) * 100
        desc = f"R{i+1}: {level:.2f} (+{res_percent:.2f}%)"
        sr_levels_to_plot.append({'level': level, 'desc': desc, 'type': 'R'})
        
    for i, level in enumerate(closest_supports):
        sup_percent = (1 - level / current_price) * 100
        desc = f"S{i+1}: {level:.2f} (-{sup_percent:.2f}%)"
        sr_levels_to_plot.append({'level': level, 'desc': desc, 'type': 'S'})

    # èª¿æ•´ Y è»¸ç¯„åœ
    min_price = df_display[['low', 'MA5', 'MA10', 'MA20', 'MA60', 'VWAP', 'BB_LOW']].min(skipna=True).min(skipna=True)
    max_price = df_display[['high', 'MA5', 'MA10', 'MA20', 'MA60', 'VWAP', 'BB_UP']].max(skipna=True).max(skipna=True)
    
    if pd.isna(min_price) or pd.isna(max_price) or min_price == max_price:
        min_price = df_display['close'].min()
        max_price = df_display['close'].max()

    price_range = max_price - min_price
    yaxis_min = min_price - price_range * 0.2 
    yaxis_max = max_price + price_range * 0.2 

    fig = make_subplots(
        rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.07,
        row_heights=[0.7, 0.15, 0.15],
        subplot_titles=(f"Kç·šåœ– ({frequency}ç·š, å«çºè«–ç­†æ®µ)", "æˆäº¤é‡", "ATR")
    )
    
    first_date = df_display['date'].iloc[0]
    last_date = df_display['date'].iloc[-1]
    date_range = last_date - first_date
    center_date = first_date + date_range / 2 

    # 6. Kç·šåœ–èˆ‡æŒ‡æ¨™ç¹ªè£½ (Traces)
    fig.add_trace(go.Candlestick(x=df_display['date'], open=df_display['open'], high=df_display['high'], low=df_display['low'], close=df_display['close'], increasing_line_color='red', decreasing_line_color='green', name=f'{frequency}ç·š'), row=1, col=1)
    
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['stop_loss'], mode='lines', line=dict(dash='dot', color='gray'), name='æ­¢æåƒ¹'), row=1, col=1)
    ma_colors = {5: 'blue', 10: 'orange', 20: 'purple', 60: 'black'}
    for ma in [5, 10, 20, 60]: fig.add_trace(go.Scatter(x=df_display['date'], y=df_display[f"MA{ma}"], mode='lines', line=dict(color=ma_colors[ma], width=1), name=f"MA{ma}"), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VWAP'], mode='lines', line=dict(color='magenta', width=2, dash='solid'), name='ä¸»åŠ›æˆæœ¬ç·š (VWAP)'), row=1, col=1)

    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['BB_UP'], mode='lines', line=dict(color='darkred', width=1, dash='dot'), name='å¸ƒæ—ä¸Šè»Œ'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['BB_LOW'], mode='lines', line=dict(color='darkgreen', width=1, dash='dot'), name='å¸ƒæ—ä¸‹è»Œ'), row=1, col=1)

    # ----------------------------------------------------
    # ğŸŒŸ ä¿®æ­£å¾Œçš„ S/R ç¹ªè£½ï¼šä½¿ç”¨ ATR åŸºç¤çš„ price_half_width
    # ----------------------------------------------------
    sr_shapes = [] 
    sr_annotations = [] 
    
    if not df_display.empty and sr_levels_to_plot:
        
        for level_data in sr_levels_to_plot:
            level = level_data['level']
            desc = level_data['desc']
            type_sr = level_data['type']
            
            # ä½¿ç”¨åŸºæ–¼ ATR çš„ price_half_width ä¾†å®šç¾©çŸ©å½¢é‚Šç•Œ
            y0_rect = level - price_half_width
            y1_rect = level + price_half_width
            
            # ç¹ªè£½çŸ©å½¢ (Shape)
            color = "rgba(255, 99, 71, 0.2)" if type_sr == 'R' else "rgba(50, 205, 50, 0.2)"
            
            fig.add_hrect(
                y0=y0_rect, y1=y1_rect, 
                row=1, col=1, fillcolor=color, layer="below", line_width=0, name=f"{type_sr}å€-{level:.2f}"
            )
            sr_shapes.append(len(fig.layout.shapes) - 1) 
            
            # ç¹ªè£½æ–‡å­—æ¨™ç±¤ (Annotation) - å±…ä¸­é¡¯ç¤º
            text_color = "#7C1D0C" if type_sr == 'R' else "#126412"
            y_anchor = "bottom" if type_sr == 'R' else "top"
            # Annotation æ”¾ç½®åœ¨çŸ©å½¢é‚Šç•Œå¤–å´
            y_pos = y1_rect if type_sr == 'R' else y0_rect
            
            fig.add_annotation(
                x=center_date, y=y_pos, 
                text=desc, showarrow=False,
                font=dict(size=12, color=text_color, weight='bold'), 
                bgcolor="rgba(255, 255, 255, 0.7)",
                yanchor=y_anchor, xshift=0 
            )
            sr_annotations.append(len(fig.layout.annotations) - 1)
            
    # ----------------------------------------------------
    
    # 7. è²·å…¥è¨Šè™Ÿ (æ¨™è¨˜åœ¨ K ç·šä¸‹æ–¹)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['Signal_VSA_Strong'], mode='markers', marker=dict(size=12, symbol='star-triangle-up', color='red', line=dict(width=1, color='black')), name='VSA å¼·å‹¢æ‹‰æŠ¬', hovertext="ä¸»åŠ›VSAå¼·å‹¢æ‹‰æŠ¬", hoverinfo='text'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['Signal_VWAP_Break'], mode='markers', marker=dict(size=10, symbol='triangle-up', color='orange', line=dict(width=1, color='black')), name='VWAP æˆæœ¬çªç ´', hovertext="ä¸»åŠ›æˆæœ¬çªç ´", hoverinfo='text'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['Signal_Accumulation_Breakout'], mode='markers', marker=dict(size=14, symbol='star', color='gold', line=dict(width=1.5, color='darkgreen')), name='ğŸš€ ä¸»åŠ›å¸ç±Œçªç ´', hovertext="ä¸»åŠ›å¸ç±Œå®Œæˆï¼Œå•Ÿå‹•æ‹‰æŠ¬ (è¤‡åˆè¨Šè™Ÿ)"), row=1, col=1)
    
    # RSI åº•èƒŒé›¢å¸ç±Œä¿¡è™Ÿ (ä½¿ç”¨ ATR14 é€²è¡Œåç§»)
    offset_divergence = df_display['ATR14'].fillna(0) * 0.2 
    y_divergence_adjusted = df_display['Signal_Divergence'] - offset_divergence
    fig.add_trace(go.Scatter(x=df_display['date'], y=y_divergence_adjusted, mode='markers', marker=dict(size=10, symbol='diamond', color='blue', line=dict(width=1, color='black')), name='RSI åº•èƒŒé›¢ (å¸ç±Œ)', hovertext="RSIåº•èƒŒé›¢å¸ç±Œ", hoverinfo='text'), row=1, col=1)

    # 8. è³£å‡ºè¨Šè™Ÿ (æ¨™è¨˜åœ¨ K ç·šä¸Šæ–¹)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['Signal_VSA_Weak'], mode='markers', marker=dict(size=12, symbol='star-triangle-down', color='green', line=dict(width=1, color='black')), name='VSA ææ…Œæ‹‹å”®', hovertext="ä¸»åŠ›VSAææ…Œæ‹‹å”®", hoverinfo='text'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['Signal_VWAP_BreakDown'], mode='markers', marker=dict(size=10, symbol='triangle-down', color='purple', line=dict(width=1, color='black')), name='VWAP æˆæœ¬è·Œç ´', hovertext="ä¸»åŠ›æˆæœ¬è·Œç ´", hoverinfo='text'), row=1, col=1)
    
    # RSI é ‚èƒŒé›¢æ´¾ç™¼ä¿¡è™Ÿ (ä½¿ç”¨ ATR14 é€²è¡Œåç§»)
    offset_top_divergence = df_display['ATR14'].fillna(0) * 0.2
    y_top_divergence_adjusted = df_display['Signal_TopDivergence'] + offset_top_divergence
    fig.add_trace(go.Scatter(x=df_display['date'], y=y_top_divergence_adjusted, mode='markers', marker=dict(size=10, symbol='diamond', color='green', line=dict(width=1, color='black')), name='RSI é ‚èƒŒé›¢ (æ´¾ç™¼)', hovertext="RSIé ‚èƒŒé›¢æ´¾ç™¼"), row=1, col=1)
    
    # 9. æˆäº¤é‡ & ATR 
    vol_color = df_display.apply(lambda row: 'red' if row['close'] > row['open'] else ('green' if row['close'] < row['open'] else 'gray'), axis=1)
    fig.add_trace(go.Bar(x=df_display['date'], y=df_display['volume'] / 1000, name='æˆäº¤é‡ (K)', marker_color=vol_color), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VOL5'] / 1000, mode='lines', line=dict(color='blue', width=1), name='VOL5 (K)'), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VOL20'] / 1000, mode='lines', line=dict(color='orange', width=1), name='VOL20 (K)'), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['ATR14'], mode='lines', line=dict(color='red', width=1), name='ATR14'), row=3, col=1)
    
    # 10. ç­†æ®µç¹ªè£½ 
    df_pivots_display_filtered = df_final[
        (df_final['Pivot_Type'] != 0) &
        (df_final['date'] >= df_display['date'].min()) &
        (df_final['date'] <= df_display['date'].max())
    ].dropna(subset=['Pivot_Price']).copy()
    
    extend_points = pd.DataFrame(columns=['date', 'Pivot_Price'])
    
    # ç­†æ®µå»¶ä¼¸é‚è¼¯ (ä¿æŒä¸è®Š)
    if last_pivot_date and not df_display.empty:
        start_index = df_display[df_display['date'] == last_pivot_date].index
        
        if not start_index.empty:
            start_index = start_index[0]
            df_extension = df_display.loc[start_index:].copy()
            current_trend_status = trend_analysis['Overall_Trend']
            
            if last_pivot_type == 1: 
                df_extension['Pivot_Price_Extension'] = df_extension['low']
                if len(df_pivots_display_filtered) >= 2:
                    B_pre = df_pivots_display_filtered.iloc[-2]['Pivot_Price']
                    if df_extension['low'].min() < B_pre:
                        current_trend_status = "âš ï¸ **æ½›åœ¨è¶¨å‹¢åè½‰/æŒçºŒä¸‹é™ (ä¸‹ç©¿å‰åº•)**"
            elif last_pivot_type == -1: 
                df_extension['Pivot_Price_Extension'] = df_extension['high']
                if len(df_pivots_display_filtered) >= 2:
                    T_pre = df_pivots_display_filtered.iloc[-2]['Pivot_Price']
                    if df_extension['high'].max() > T_pre:
                        current_trend_status = "âœ… **è¶¨å‹¢æŒçºŒ (ä¸Šç©¿å‰é«˜)**"
            
            if 'Pivot_Price_Extension' in df_extension.columns:
                df_extension.loc[start_index, 'Pivot_Price_Extension'] = df_pivots_display_filtered.iloc[-1]['Pivot_Price']
                extend_points = df_extension[['date', 'Pivot_Price_Extension']].rename(columns={'Pivot_Price_Extension': 'Pivot_Price'})

            trend_analysis['Overall_Trend'] = current_trend_status
            trend_desc_final = current_trend_status 
            
    if not df_pivots_display_filtered.empty:
        plot_points = df_pivots_display_filtered[['date', 'Pivot_Price']].copy()
        
        if not extend_points.empty:
            start_date_filter = plot_points['date'].max()
            new_extension = extend_points[extend_points['date'] >= start_date_filter]
            plot_points = pd.concat([plot_points, new_extension], ignore_index=True).drop_duplicates(subset=['date'], keep='last')
            
        fig.add_trace(go.Scatter(x=plot_points['date'], y=plot_points['Pivot_Price'], mode='lines', line=dict(color='black', width=2, dash='solid'), name='ç­†æ®µè¶¨å‹¢é€£ç·š (åš´æ ¼ç­†æ®µ)'), row=1, col=1)

        df_top = df_pivots_display_filtered[df_pivots_display_filtered['Pivot_Type']==1]
        fig.add_trace(go.Scatter(x=df_top['date'], y=df_top['Pivot_Price'], mode='markers', marker=dict(size=8, color='black', symbol='circle', line=dict(width=1, color='black')), name='ç­†æ®µé ‚é»', hoverinfo='text', text=[f"ç­†æ®µé ‚: {p:.2f}" for p in df_top['Pivot_Price']], uid='top_pivot_marker'), row=1, col=1)
        
        df_bottom = df_pivots_display_filtered[df_pivots_display_filtered['Pivot_Type']==-1]
        fig.add_trace(go.Scatter(x=df_bottom['date'], y=df_bottom['Pivot_Price'], mode='markers', marker=dict(size=8, color='black', symbol='circle', line=dict(width=1, color='black')), name='ç­†æ®µåº•é»', hoverinfo='text', text=[f"ç­†æ®µåº•: {p:.2f}" for p in df_bottom['Pivot_Price']], uid='bottom_pivot_marker'), row=1, col=1)
        
    # ----------------- S/R é–‹é—œæŒ‰éˆ•è¨­ç½® (ä½¿ç”¨æ‰€æœ‰è¿½è¹¤åˆ°çš„ç´¢å¼•) -----------------
    
    # 1. å®šç¾© 'é¡¯ç¤º' ç‹€æ…‹ä¸‹çš„åƒæ•¸
    show_shapes_args = {f'shapes[{i}].visible': True for i in sr_shapes}
    show_anno_args = {f'annotations[{i}].visible': True for i in sr_annotations}
    show_args = {**show_shapes_args, **show_anno_args}

    # 2. å®šç¾© 'éš±è—' ç‹€æ…‹ä¸‹çš„åƒæ•¸
    hide_shapes_args = {f'shapes[{i}].visible': False for i in sr_shapes}
    hide_anno_args = {f'annotations[{i}].visible': False for i in sr_annotations}
    hide_args = {**hide_shapes_args, **hide_anno_args}
    
    # 3. å‰µå»ºæŒ‰éˆ•åˆ—è¡¨
    buttons = [
        dict(
            label="éš±è— S/R", 
            method="relayout",
            args=[hide_args],
        ),
        dict(
            label="é¡¯ç¤º S/R",
            method="relayout",
            args=[show_args]
        )
    ]
    # ----------------------------------------------------

    # 11. æ›´æ–°åœ–è¡¨ä½ˆå±€ (åŒ…å« updatemenus)
    stock_name = df_display['stock_name'].iloc[0] if 'stock_name' in df_display.columns and not df_display.empty else stock_id_clean
    first_date_str = df_display['date'].iloc[0].strftime("%Y-%m-%d")
    last_date_str = df_display['date'].iloc[-1].strftime("%Y-%m-%d")

    fig.update_layout(
        title=dict(
            text=f"{stock_id_clean} ({stock_name}) - {frequency}ç·šè¶¨å‹¢: {trend_desc_final} ({first_date_str} ~ {last_date_str})",
            x=0.5, xanchor='center'
        ),
        xaxis_rangeslider_visible=False, hovermode='x unified', dragmode='drawline',
        newshape=dict(line_color='black', line_width=2),
        modebar_add=['drawline', 'drawopenpath', 'drawrect', 'drawcircle', 'eraseshape'],
        yaxis=dict(range=[yaxis_min, yaxis_max]),
        height=1200,

        # S/R é–‹é—œæŒ‰éˆ•
        updatemenus=[
            dict(
                type="buttons",
                direction="left",
                buttons=buttons,
                pad={"r": 10, "t": 10},
                showactive=True,
                x=1.0, 
                xanchor="right",
                y=1.1, 
                yanchor="top"
            )
        ]
    )

    fig.update_yaxes(title_text="æˆäº¤é‡ (K)", row=2, col=1)
    
    html = fig.to_html(include_plotlyjs='cdn')
    
    return html, None, trend_desc_final, rebound_desc, trend_class
# ----------------- Flask è·¯ç”±éƒ¨åˆ† -----------------
# ----------------- è¼”åŠ©å‡½æ•¸ï¼šç²å–æœ€æ„›ç‹€æ…‹å’Œå‚™è¨» -----------------

# ----------------- è¼”åŠ©å‡½æ•¸ï¼šæœ€æ„›æ“ä½œ (ä¿æŒä¸è®Š) -----------------

def get_favorite_status_and_note(stock_id):
    """æª¢æŸ¥è‚¡ç¥¨æ˜¯å¦åœ¨æœ€æ„›ä¸­ï¼Œä¸¦è¿”å› is_favorite ç‹€æ…‹å’Œ note å…§å®¹ã€‚"""
    try:
        res = requests.get(
            f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", 
            headers=headers, 
            params={"stock_id": f"eq.{stock_id}", "select": "stock_id,note"},
            timeout=5
        )
        res.raise_for_status()
        data = res.json()
        
        if data: return True, data[0].get('note', '') or '' 
        else: return False, ''
    except Exception as e:
        print(f"Error checking favorite status for {stock_id}: {e}")
        return False, ''

def save_favorite_status(stock_id, is_favorite, note=''):
    """åœ¨ Supabase ä¸­æ›´æ–°è‚¡ç¥¨çš„æœ€æ„›ç‹€æ…‹å’Œå‚™è¨» (æ’å…¥/åˆªé™¤/æ›´æ–°)ã€‚"""
    try:
        if is_favorite:
            # å˜—è©¦æ›´æ–° (å¦‚æœå­˜åœ¨)
            update_res = requests.patch(
                f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}?stock_id=eq.{stock_id}",
                headers={**headers, "Prefer": "return=representation"},
                data=json.dumps({"note": note, "stock_name": f"è‚¡{stock_id}"})
            )
            update_res.raise_for_status()
            
            # å¦‚æœæ›´æ–°å½±éŸ¿è¡Œæ•¸ç‚º 0 (å³è‚¡ç¥¨ä¸å­˜åœ¨)ï¼Œå‰‡åŸ·è¡Œæ’å…¥
            if not update_res.json():
                insert_data = {"stock_id": stock_id, "stock_name": f"è‚¡{stock_id}", "note": note}
                insert_res = requests.post(
                    f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}",
                    headers=headers,
                    data=json.dumps(insert_data)
                )
                insert_res.raise_for_status()
            
            return True, "å·²åŠ å…¥æœ€æ„›ä¸¦æ›´æ–°å‚™è¨»"
        
        else:
            # åŸ·è¡Œåˆªé™¤æ“ä½œ
            delete_res = requests.delete(
                f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}?stock_id=eq.{stock_id}",
                headers=headers
            )
            delete_res.raise_for_status()
            return True, "å·²å¾æœ€æ„›ä¸­ç§»é™¤"
            
    except requests.exceptions.HTTPError as e:
        error_msg = e.response.json().get('message', f"HTTP Error: {e.response.status_code}")
        print(f"Supabase HTTP éŒ¯èª¤: {error_msg}")
        return False, error_msg
    except Exception as e:
        print(f"æœ€æ„›æ“ä½œæ™‚ç™¼ç”Ÿé€£ç·š/å…§éƒ¨éŒ¯èª¤: {e}")
        return False, str(e)

def favorites_clear_all():
    """åˆªé™¤æ‰€æœ‰æœ€æ„›è¨˜éŒ„ã€‚"""
    try:
        res = requests.delete(
            f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}?stock_id=gte.0",
            headers=headers
        )
        res.raise_for_status()
        return True, "æˆåŠŸæ¸…é™¤æ‰€æœ‰æœ€æ„›è‚¡ç¥¨"
    except Exception as e:
        print(f"æ¸…é™¤æœ€æ„›æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False, str(e)


# ----------------- Flask è·¯ç”±éƒ¨åˆ† (å·²ä¿®æ­£ n_sr_levels å‚³é) -----------------

@app.route('/')
def index():
    # å‡è¨­ index.html å­˜åœ¨
    return render_template('index.html')

@app.route('/query', methods=['POST'])
def query():
    stock_id = request.form['stock_id'].strip()
    simple_mode = request.form.get('simple_mode') == '1'
    num_rows = request.form.get('num_rows', type=int, default=30)
    frequency = request.form.get('frequency', 'D')
    n_sr_levels = request.form.get('n_sr_levels', type=int, default=3)
    
    chart_html, error, trend_desc, rebound_desc, trend_class = generate_chart(
        stock_id, simple_mode=simple_mode, num_rows=num_rows, 
        frequency=frequency, n_sr_levels=n_sr_levels
    )
    
    if error: return f"<h2>{error}</h2><a href='/'>è¿”å›</a>"
    
    is_favorite, favorite_note = get_favorite_status_and_note(stock_id) 
    
    return render_template(
        'chart.html', 
        chart_html=chart_html, stock_id=stock_id, stock_list=stock_id, current_index=0, 
        simple_mode=simple_mode, num_rows=num_rows, is_favorite=is_favorite,
        favorite_note=favorite_note, trend_desc=trend_desc, rebound_desc=rebound_desc, 
        trend_class=trend_class, frequency=frequency, current_n_sr_levels=n_sr_levels # ä½¿ç”¨ä¿®æ­£å¾Œçš„è®Šæ•¸å
    )

@app.route('/chart/<stock_id>/')
@app.route('/chart/<stock_id>')
def chart_from_list(stock_id):
    stock_id = stock_id.strip()
    simple_mode = request.args.get('simple_mode') == '1'
    num_rows = request.args.get('num_rows', type=int, default=30)
    stock_list = request.args.get('list', '')
    frequency = request.args.get('frequency', 'D')
    n_sr_levels = request.args.get('n_sr_levels', type=int, default=3)

    stock_ids = stock_list.split(',') if stock_list else [stock_id]
    current_index = 0
    try:
        current_index = stock_ids.index(stock_id)
    except ValueError:
        stock_ids = [stock_id]; current_index = 0
    current_stock = stock_ids[current_index] 
    
    chart_html, error, trend_desc, rebound_desc, trend_class = generate_chart(
        current_stock, simple_mode=simple_mode, num_rows=num_rows, 
        frequency=frequency, n_sr_levels=n_sr_levels
    )
    
    if error: return f"<h2>{error}</h2><a href='/'>è¿”å›</a>"
    
    is_favorite, favorite_note = get_favorite_status_and_note(current_stock)

    return render_template(
        'chart.html', 
        chart_html=chart_html, stock_id=current_stock, stock_list=','.join(stock_ids), 
        current_index=current_index, simple_mode=simple_mode, num_rows=num_rows, 
        is_favorite=is_favorite, favorite_note=favorite_note, trend_desc=trend_desc,
        rebound_desc=rebound_desc, trend_class=trend_class, frequency=frequency,
        current_n_sr_levels=n_sr_levels # ä½¿ç”¨ä¿®æ­£å¾Œçš„è®Šæ•¸å
    )

# ----------------- Favorites è·¯ç”± (å·²ä¿®æ­£ n_sr_levels å‚³é) -----------------
@app.route('/filter', methods=['POST'])
def filter_stocks():
    # ------------------ ç²å–æ‰€æœ‰ç¯©é¸åŠé…ç½®åƒæ•¸ ------------------
    volume_min = request.form.get('volume_min', type=float, default=0)
    trend_type = request.form.get('trend_type', '')
    # æ³¨æ„ï¼šå°‡ 'change_min' (å‰ç«¯åç¨±) æ˜ å°„åˆ° 'adr14_min' (å¾Œç«¯è®Šæ•¸å)
    adr14_min = request.form.get('change_min', type=float, default=0) 
    
    # é é¢é…ç½®åƒæ•¸
    simple_mode = request.form.get('simple_mode') == '1'
    num_rows = request.form.get('num_rows', type=int, default=60)
    recent_days = request.form.get('recent_days', type=int, default=30)
    frequency = request.form.get('frequency', 'D')
    # ğŸŒŸ ä¿®æ­£é» 1: ç¢ºä¿è®€å– n_sr_levels åƒæ•¸
    n_sr_levels = request.form.get('n_sr_levels', type=int, default=3) 

    # ------------------ Supabase æ•¸æ“šç²å–é‚è¼¯ ------------------
    recent_date = (datetime.today() - timedelta(days=recent_days)).strftime("%Y-%m-%d")
    all_data = []
    limit = 1000
    offset = 0

    while True:
        try:
            # ğŸŒŸ å‡è¨­ SUPABASE_URL å’Œ headers æ˜¯å…¨åŸŸå¯ç”¨çš„
            params = {
                "latest_volume": f"gte.{int(volume_min)}",
                "adr14": f"gte.{adr14_min}",
                "latest_date": f"gte.{recent_date}",
                # åƒ…åœ¨ trend_type å­˜åœ¨æ™‚åŠ å…¥ç¯©é¸æ¢ä»¶
                "trend": f"eq.{trend_type}" if trend_type else None, 
                "order": "latest_date.desc", "limit": limit, "offset": offset, "select": "*"
            }
            # ç§»é™¤ None å€¼çš„åƒæ•¸ï¼Œé˜²æ­¢ Supabase å ±éŒ¯
            params = {k: v for k, v in params.items() if v is not None}
            
            res = requests.get(f"{SUPABASE_URL}/rest/v1/quick_view", headers=headers,
                               params=params, timeout=30)
            
            res.raise_for_status()
            data = res.json()
            if not data: break
            all_data.extend(data)
            if len(data) < limit: break
            offset += limit
            
        except requests.exceptions.HTTPError as e:
            # æ•ç²ä¸¦é¡¯ç¤º Supabase è¿”å›çš„å…·é«”éŒ¯èª¤ä¿¡æ¯
            return f"<h2>Supabase HTTP éŒ¯èª¤: {e.response.json().get('message', e)}</h2><a href='/'>è¿”å›</a>"
        except Exception as e: 
            return f"<h2>Supabase è®€å– QUICK_VIEW å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"

    # ------------------ çµæœè™•ç†èˆ‡ HTML ç”Ÿæˆ ------------------
    if not all_data: return "<h2>æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨</h2><a href='/'>è¿”å›</a>"
    
    df = pd.DataFrame(all_data)
    stock_ids = [str(sid) for sid in df['stock_id']]
    count = len(df)
    list_param = urllib.parse.quote(','.join(stock_ids))
    
    html = (f"<h2>ç¯©é¸çµæœï¼ˆå…± {count} ç­†ï¼‰</h2>" 
            "<table border='1' cellpadding='6' style='margin-left:0; text-align:left;'>" 
            "<thead><tr>" 
            "<th>è‚¡ç¥¨ä»£è™Ÿ</th><th>è‚¡ç¥¨åç¨±</th><th>æˆäº¤é‡</th>" 
            "<th>ADR14(%)</th><th>14å¤©å¹³å‡æˆäº¤é‡</th><th>è¶¨å‹¢</th>" 
            "</tr></thead><tbody>")
            
    for idx, row in df.iterrows():
        simple_param = "1" if simple_mode else "0"
        
        # ğŸŒŸ ä¿®æ­£é» 2: åœ¨è·³è½‰é€£çµä¸­åŠ å…¥ n_sr_levels åƒæ•¸
        chart_url = (f"/chart/{row['stock_id']}?"
                     f"simple_mode={simple_param}&"
                     f"num_rows={num_rows}&"
                     f"list={list_param}&"
                     f"index={idx}&"
                     f"frequency={frequency}&"
                     f"n_sr_levels={n_sr_levels}")
                     
        html += (f"<tr>" 
                 f"<td><a href='{chart_url}'>{row['stock_id']}</a></td>" 
                 f"<td>{row['stock_name']}</td>" 
                 f"<td>{int(row['latest_volume'])}</td>" 
                 f"<td>{row['adr14']:.2f}</td>" 
                 f"<td>{int(row['avg_volume_14'])}</td>" 
                 f"<td>{row['trend']}</td>" 
                 f"</tr>")
                 
    html += "</tbody></table><br><a href='/'>è¿”å›</a>"
    return html

@app.route('/favorites', methods=['GET'])
def favorites_page():
    simple_mode = request.args.get('simple_mode') == '1'
    num_rows = request.args.get('num_rows', type=int, default=30)
    frequency = request.args.get('frequency', 'D')
    n_sr_levels = request.args.get('n_sr_levels', type=int, default=3)
    
    params_string = (f"simple_mode={'1' if simple_mode else '0'}&num_rows={num_rows}&frequency={frequency}&n_sr_levels={n_sr_levels}")
    
    try:
        res = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}?select=stock_id,stock_name,note&order=created_at.desc", headers=headers)
        res.raise_for_status()
        fav_data = res.json()
    except Exception as e: return f"<h2>è®€å–æœ€æ„›è‚¡ç¥¨å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"
    
    if not fav_data: return "<h2>å°šç„¡æœ€æ„›è‚¡ç¥¨</h2><a href='/'>è¿”å›</a>"
    
    stock_ids = [item['stock_id'] for item in fav_data]
    list_param = urllib.parse.quote(','.join(stock_ids))
    note_map = {item['stock_id']: item.get('note', '') or '' for item in fav_data}
    
    try:
        res_qv = requests.get(
            f"{SUPABASE_URL}/rest/v1/{QUICK_VIEW_TABLE}", 
            headers=headers, 
            params={"stock_id": f"in.({','.join(stock_ids)})", "select": "*"}
        )
        res_qv.raise_for_status()
        qv_data = res_qv.json()
    except Exception as e: return f"<h2>è®€å–æœ€æ„›è‚¡ç¥¨å¿«ç…§è³‡æ–™å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"

    df_qv = pd.DataFrame(qv_data)
    df_qv['stock_id'] = df_qv['stock_id'].astype(str)
    df_qv = df_qv.set_index('stock_id').reindex(stock_ids).reset_index() 
    count = len(df_qv)
    
    html = (f"<h2>æˆ‘çš„æœ€æ„›ï¼ˆå…± {count} ç­†ï¼‰</h2>" 
            f"<form method='post' action='/favorites_clear?{params_string}' onsubmit=\"return confirm('ç¢ºå®šè¦åˆªé™¤æ‰€æœ‰æœ€æ„›å—ï¼Ÿ');\">" 
            "<button type='submit' style='margin-bottom:10px;'>åˆªé™¤å…¨éƒ¨æœ€æ„›</button>" 
            "</form>" 
            "<table border='1' cellpadding='6' style='margin-left:0; text-align:left;'><thead><tr><th>è‚¡ç¥¨ä»£è™Ÿ</th><th>è‚¡ç¥¨åç¨±</th><th>å‚™è¨»</th><th>æˆäº¤é‡</th><th>ADR14(%)</th><th>14å¤©å¹³å‡æˆäº¤é‡</th><th>è¶¨å‹¢</th></tr></thead><tbody>")
            
    for row in df_qv.itertuples():
        stock_id = str(row.stock_id)
        current_index = stock_ids.index(stock_id) 
        current_note = note_map.get(stock_id, '') 
        simple_param = "1" if simple_mode else "0"
        
        # ä¿®æ­£è·³è½‰é€£çµï¼šç¢ºä¿é€£çµåŒ…å«æ‰€æœ‰åƒæ•¸
        html += (f"<tr>" 
                  f"<td><a href='/chart/{stock_id}?simple_mode={simple_param}&num_rows={num_rows}&list={list_param}&index={current_index}&frequency={frequency}&n_sr_levels={n_sr_levels}'>{stock_id}</a></td>" 
                  f"<td>{getattr(row, 'stock_name', 'N/A')}</td><td>{current_note}</td><td>{int(row.latest_volume)}</td><td>{row.adr14:.2f}</td><td>{int(row.avg_volume_14)}</td><td>{row.trend}</td>" 
                  f"</tr>")
                  
    html += "</tbody></table><br><a href='/'>è¿”å›</a>"
    return html

# ----------------- Favorite è·¯ç”±ï¼šè§£æ±º 415 éŒ¯èª¤ (æœŸæœ› JSON) -----------------
@app.route('/favorite', methods=['POST'])
def favorite():
    """
    è™•ç†å–®ä¸€è‚¡ç¥¨çš„æ”¶è—/å–æ¶ˆæ”¶è—åŠå‚™è¨»æ›´æ–°ã€‚
    æœŸæœ›æ¥æ”¶ Content-Type: application/json æ•¸æ“šã€‚
    """
    
    # ğŸŒŸ ä¿®æ­£é»ï¼šä½¿ç”¨ request.json è®€å– JSON æ•¸æ“š
    data = request.json
    
    if not data:
        # å¦‚æœä¸æ˜¯ JSON æ ¼å¼ï¼Œæœƒæ˜¯ Noneï¼Œè¿”å› 400 (æˆ– 415ï¼Œä½†æˆ‘å€‘ä¸»å‹•è¿”å› 400 æ›´æ¸…æ™°)
        return jsonify({'success': False, 'message': 'è«‹æ±‚æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º JSON'}), 400
        
    stock_id = data.get('stock_id')
    # ğŸŒŸ æ¥æ”¶ç›®æ¨™æ”¶è—ç‹€æ…‹
    is_favorite = data.get('is_favorite') 
    note = data.get('note', '')

    if not stock_id:
        return jsonify({'success': False, 'message': 'ç¼ºå°‘è‚¡ç¥¨ä»£ç¢¼'}), 400
    
    if is_favorite is None:
        return jsonify({'success': False, 'message': 'ç¼ºå°‘æ”¶è—ç‹€æ…‹ (is_favorite)'}), 400
        
    # æ ¹æ“š is_favorite çš„ç‹€æ…‹åŸ·è¡Œæ”¶è—/å–æ¶ˆæ”¶è—/æ›´æ–°å‚™è¨»
    success, message = save_favorite_status(stock_id, is_favorite, note)
        
    if success:
        return jsonify({
            'success': True, 
            'message': message, 
            'favorite': is_favorite # è¿”å›æ–°çš„æ”¶è—ç‹€æ…‹
        }), 200
    else:
        return jsonify({'success': False, 'message': f"æ“ä½œæœ€æ„›å¤±æ•—: {message}"}), 500

# ----------------- Favorites Clear è·¯ç”± (ä¿æŒä¸è®Š) -----------------
@app.route('/favorites_clear', methods=['POST'])
def favorites_clear():
    simple_mode = request.args.get('simple_mode', '0')
    num_rows = request.args.get('num_rows', type=int, default=30)
    frequency = request.args.get('frequency', 'D')
    n_sr_levels = request.args.get('n_sr_levels', type=int, default=3)

    success, message = favorites_clear_all()
    
    redirect_url = url_for('favorites_page', 
                            simple_mode=simple_mode, 
                            num_rows=num_rows, 
                            frequency=frequency, 
                            n_sr_levels=n_sr_levels)
    
    if success:
        return redirect(redirect_url) 
    else:
        return f"<h2>æ¸…é™¤å¤±æ•—: {message}</h2><a href='{redirect_url}'>è¿”å›æœ€æ„›é é¢</a>", 500


# ----------------- é‹è¡Œç¨‹å¼ -----------------
if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=True)