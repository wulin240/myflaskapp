from flask import Flask, render_template, request, jsonify
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import urllib.parse
from datetime import datetime, timedelta

app = Flask(__name__)

# ----------------- Supabase è¨­å®š -----------------
# è«‹å°‡é€™è£¡æ›¿æ›æˆæ‚¨çš„ Supabase å°ˆæ¡ˆè³‡è¨Š
SUPABASE_URL = "https://djhdpltrhlhqfxmwniki.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImRqaGRwbHRyaGxocWZ4bXduaWtpIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjMwNjQwODgsImV4cCI6MjA3ODY0MDA4OH0.jwSPe-HMHxv2xGCjS42O5Cjby0KtgsHEStlQWs0cyPk"
TABLE_NAME = "stock_data"
FAVORITE_TABLE = "favorites"

headers = {
    "apikey": SUPABASE_KEY.strip(),
    "Authorization": f"Bearer {SUPABASE_KEY.strip()}"
}

# ----------------- è¼”åŠ©å‡½æ•¸ï¼šæœ€æ„›è‚¡ç¥¨æª¢æŸ¥ (ä¿®æ­£ä½ç½®ï¼šç§»åˆ°æ‰€æœ‰è·¯ç”±ä¹‹å‰) -----------------
def is_favorite(stock_id):
    try:
        # ä½¿ç”¨ headers ç¢ºä¿æˆæ¬Š
        res = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params={"stock_id": f"eq.{stock_id}"}, timeout=10)
        res.raise_for_status()
        return len(res.json()) > 0
    except Exception as e:
        # å³ä½¿ Supabase é€£ç·šå¤±æ•—ï¼Œä¹Ÿä¸æ‡‰è©²å½±éŸ¿ä¸»ç¨‹å¼åŸ·è¡Œ
        print(f"âš ï¸ æª¢æŸ¥æœ€æ„›å¤±æ•—: {e}")
        return False
        
# ----------------- æŠ“å–è‚¡ç¥¨è³‡æ–™ -----------------
def fetch_stock_data(stock_id):
    stock_id_clean = stock_id.replace(".TW","").replace(".TWO","")
    params = {"stock_id": f"eq.{stock_id_clean}", "order": "date.asc", "select": "*, stock_name"} 

    try:
        res = requests.get(
            f"{SUPABASE_URL}/rest/v1/{TABLE_NAME}", headers=headers, params=params, timeout=30
        )
        res.raise_for_status()
        data = res.json()
        if not data: return pd.DataFrame()
        df = pd.DataFrame(data)
        df['date'] = pd.to_datetime(df['date'])
        return df
    except Exception as e:
        print(f"âš ï¸ Supabase è®€å– {stock_id} å¤±æ•—: {e}")
        return pd.DataFrame()

# ----------------- æ•¸æ“šè™•ç†æ ¸å¿ƒåŠŸèƒ½ -----------------

def convert_to_weekly(df_daily):
    """å°‡æ—¥ç·šæ•¸æ“š (OHLCV) è½‰æ›ç‚ºé€±ç·šæ•¸æ“šã€‚"""
    if df_daily.empty:
        return df_daily
    
    df = df_daily.set_index('date')
    weekly_data = df.resample('W').agg({
        'open': 'first',        
        'high': 'max',          
        'low': 'min',           
        'close': 'last',        
        'volume': 'sum'        
    })
    
    df_weekly = weekly_data.dropna(subset=['open'])
    df_weekly = df_weekly.reset_index()
    if not df_daily.empty and 'stock_name' in df_daily.columns:
        df_weekly['stock_name'] = df_daily['stock_name'].iloc[-1]
    if not df_daily.empty and 'stock_id' in df_daily.columns:
        df_weekly['stock_id'] = df_daily['stock_id'].iloc[-1]
    
    return df_weekly


def kline_merge(df):
    """ğŸŒŸ ä¿®æ­£ Kç·šåˆä½µï¼šæ¡ç”¨æ›´ç©©å¥çš„åŒ…å«é—œä¿‚åˆ¤å®šé‚è¼¯ï¼Œè™•ç†é‚Šç•Œæƒ…æ³ã€‚"""
    if df.empty: return df
    df_raw = df.copy()
    processed_kline = []
    
    # è¨­ç½®ç´¢å¼•ç‚º date (å¦‚æœå°šæœªè¨­ç½®)
    df_raw = df_raw.set_index('date')  
    
    current_kline = {col: df_raw.iloc[0][col] for col in ['open', 'high', 'low', 'close', 'volume']}
    current_kline['Index'] = df_raw.index[0] # è¨˜éŒ„åˆä½µ K ç·šçš„æ—¥æœŸ

    for i in range(1, len(df_raw)):
        next_row = df_raw.iloc[i]
        
        next_kline = {col: next_row[col] for col in ['open', 'high', 'low', 'close', 'volume']}
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºåŒ…å«é—œä¿‚ï¼šç¬¬äºŒæ ¹ K ç·šè¢«ç¬¬ä¸€æ ¹ K ç·šåŒ…å« æˆ– ç¬¬äºŒæ ¹ K ç·šåŒ…å«ç¬¬ä¸€æ ¹ K ç·š
        is_inclusion = (
            (next_row['high'] <= current_kline['high'] and next_row['low'] >= current_kline['low']) or
            (next_row['high'] >= current_kline['high'] and next_row['low'] <= current_kline['low'])
        )
        
        if is_inclusion:
            # åˆä½µï¼šæ›´æ–°é«˜é»/ä½é» (å–æ¥µå€¼)
            current_kline['high'] = max(current_kline['high'], next_row['high'])
            current_kline['low'] = min(current_kline['low'], next_row['low'])
            # åˆä½µï¼šæˆäº¤é‡å¿…é ˆç´¯åŠ 
            current_kline['volume'] += next_row['volume']
            # åˆä½µï¼šæ”¶ç›¤åƒ¹ä»¥**è¢«åŒ…å« K ç·šçš„æ”¶ç›¤åƒ¹**ç‚ºæº–ï¼ˆç¢ºä¿æ™‚é–“è»¸çµ‚é»æ­£ç¢ºï¼‰
            current_kline['close'] = next_row['close']  
            # ğŸŒŸ ä¿®æ­£é‚Šç•Œï¼šæ›´æ–°åˆä½µ K ç·šçš„æ—¥æœŸç‚ºæœ€æ–° K ç·šçš„æ—¥æœŸ
            current_kline['Index'] = df_raw.index[i]  
        else:
            # ä¸åŒ…å«ï¼šå°‡ç•¶å‰åˆä½µ K ç·šåŠ å…¥çµæœï¼Œä¸¦é–‹å§‹æ–°çš„ K ç·š
            processed_kline.append(current_kline)
            current_kline = next_kline
            current_kline['Index'] = df_raw.index[i]
            
    processed_kline.append(current_kline)
    
    # æ¢å¾© date æ¬„ä½
    df_merged = pd.DataFrame(processed_kline).set_index('Index').rename_axis('date').reset_index()
    df_merged['date'] = pd.to_datetime(df_merged['date'])  
    return df_merged


def find_divergence(df_merged):
    """ğŸŒŸ ä¿®æ­£åˆ†å‹åˆ¤æ–·ï¼šæ¡ç”¨åŒ…å«æˆ–ç­‰æ–¼çš„å¯¬é¬†æ¨™æº–ã€‚"""
    df = df_merged.copy()
    
    df['H_prev'], df['H_next'] = df['high'].shift(1), df['high'].shift(-1)
    df['L_prev'], df['L_next'] = df['low'].shift(1), df['low'].shift(-1)

    # ğŸŒŸ å¯¬é¬†é ‚åˆ†å‹ï¼šä¸­é–“ K ç·šé«˜é» >= å…©å´ K ç·šé«˜é»
    df['Is_Top_Divergence'] = (df['high'] >= df['H_prev']) & (df['high'] >= df['H_next'])
    # ğŸŒŸ å¯¬é¬†åº•åˆ†å‹ï¼šä¸­é–“ K ç·šä½é» <= å…©å´ K ç·šä½é»
    df['Is_Bottom_Divergence'] = (df['low'] <= df['L_prev']) & (df['low'] <= df['L_next'])

    df['Is_Top_Divergence'] = df['Is_Top_Divergence'].fillna(False)
    df['Is_Bottom_Divergence'] = df['Is_Bottom_Divergence'].fillna(False)
    
    df['Top_Price'] = np.where(df['Is_Top_Divergence'], df['high'], np.nan)
    df['Bottom_Price'] = np.where(df['Is_Bottom_Divergence'], df['low'], np.nan)
    return df


def filter_pivots_for_stroke(df_result, df_original):
    """éæ¿¾é€£çºŒè½‰æŠ˜é»ï¼Œä¸¦å°‡åˆ†å‹çµæœåˆä½µå›åŸå§‹Kç·šæ•¸æ“š (å„ªåŒ–ç‰ˆ)
    ğŸŒŸ è¿”å›æœ€å¾Œä¸€å€‹æœ‰æ•ˆåˆ†å‹é»çš„æ—¥æœŸå’Œé¡å‹ï¼Œç”¨æ–¼å¯¦æ™‚ç­†æ®µå»¶ä¼¸ã€‚
    """
    
    df_original['date'] = pd.to_datetime(df_original['date'])
    if df_original.empty:  
        df_original['Pivot_Type'] = 0
        df_original['Pivot_Price'] = np.nan
        return df_original, None, 0 # (df_final, last_pivot_date, last_pivot_type)

    pivot_points = df_result[df_result['Is_Top_Divergence'] | df_result['Is_Bottom_Divergence']].copy()

    if pivot_points.empty:  
        df_original['Pivot_Type'] = 0
        df_original['Pivot_Price'] = np.nan
        return df_original, None, 0
        
    # æ‡‰ç”¨é€£çºŒè½‰æŠ˜é»éæ¿¾ï¼ˆç¢ºä¿é ‚åº•é ‚åº•äº¤æ›¿ï¼‰
    pivot_points['Type'] = np.where(pivot_points['Is_Top_Divergence'], 1, -1)
    final_pivots_list = []
    last_type = 0
    last_date = None
    last_price = np.nan

    for idx, row in pivot_points.iterrows():
        current_type = row['Type']
        if current_type != last_type:
            row['Pivot_Price_Calc'] = row['Top_Price'] if row['Type'] == 1 else row['Bottom_Price']
            final_pivots_list.append(row)
            last_type = current_type
            last_date = row['date']
            last_price = row['Pivot_Price_Calc']

    df_filtered = pd.DataFrame(final_pivots_list)
    
    df_filtered['date'] = pd.to_datetime(df_filtered['date'])

    df_pivot_data = df_filtered[['date', 'Type', 'Pivot_Price_Calc']].rename(columns={
        'Type': 'Pivot_Type',
        'Pivot_Price_Calc': 'Pivot_Price'
    })
    
    # å°‡åˆ†å‹çµæœåˆä½µå›åŸå§‹æ•¸æ“š (df_original)
    df_merged = df_original.merge(
        df_pivot_data,
        on='date',  
        how='left'
    )
    
    df_merged['Pivot_Type'] = df_merged['Pivot_Type'].fillna(0).astype(int)
    
    return df_merged, last_date, last_type

def analyze_trend_by_pivots(pivot_df):
    """åŸºæ–¼æœ‰æ•ˆè½‰æŠ˜é»åˆ¤æ–·é ‚åº•è¶¨å‹¢ (HH/HL)"""
    if pivot_df.empty or len(pivot_df) < 4:  
        return {'Overall_Trend': "çµæ§‹æ•¸æ“šä¸è¶³ (éœ€è‡³å°‘å››å€‹æœ‰æ•ˆè½‰æŠ˜é»)"}

    tops = pivot_df[pivot_df['Pivot_Type'] == 1]['Pivot_Price'].dropna()
    bottoms = pivot_df[pivot_df['Pivot_Type'] == -1]['Pivot_Price'].dropna()

    if len(tops) < 2 or len(bottoms) < 2:
        return {'Overall_Trend': "çµæ§‹æ•¸æ“šä¸è¶³ (éœ€è‡³å°‘å…©å€‹é ‚é»å’Œå…©å€‹åº•é»)"}

    T2, T1 = tops.iloc[-1], tops.iloc[-2]
    B2, B1 = bottoms.iloc[-1], bottoms.iloc[-2]

    is_hh, is_hl = T2 > T1, B2 > B1
    is_lh, is_ll = T2 < T1, B2 < B1

    trend_result = "ç›¤æ•´/å¾…ç¢ºèª"
    if is_hh and is_hl: trend_result = "âœ… ä¸Šå‡è¶¨å‹¢ (Higher Highs & Higher Lows)"
    elif is_lh and is_ll: trend_result = "ğŸ”» ä¸‹é™è¶¨å‹¢ (Lower Highs & Lower Lows)"
    elif is_hh and is_ll: trend_result = "âš ï¸ æ“´å¼µçµæ§‹ (é«˜é»æŠ¬é«˜, ä½é»é™ä½)"
    elif is_lh and is_hl: trend_result = "â³ æ”¶æ–‚çµæ§‹ (é«˜é»é™ä½, ä½é»æŠ¬é«˜)"
        
    return {'Overall_Trend': trend_result}

def check_rebound_signal(df_full_processed, trend_period=90):
    """çµæ§‹å›èª¿èµ·æ¼²ä¿¡è™Ÿæª¢æŸ¥"""
    if len(df_full_processed) < trend_period + 5:
        return False, "æ•¸æ“šä¸è¶³ä»¥åˆ¤æ–·é•·ç·šè¶¨å‹¢"

    df_check = df_full_processed.iloc[-trend_period:].copy()
    pivot_df = df_check[df_check['Pivot_Type'] != 0].copy()
    current = df_check.iloc[-1]
    prev = df_check.iloc[-2]

    # --- 1. çµæ§‹è¶¨å‹¢ç¢ºèª (Stage I) ---
    trend_result = analyze_trend_by_pivots(pivot_df)['Overall_Trend']
    is_high_level_trend = ('ä¸Šå‡è¶¨å‹¢' in trend_result)
    is_ma_aligned = (df_check['MA60'].iloc[-1] > df_check['MA60'].iloc[0]) and (current['close'] > current['MA60'])
    
    if not (is_high_level_trend and is_ma_aligned):
        return False, f"âŒ é•·ç·šè¶¨å‹¢ä¸ç¬¦åˆ HH/HL ä¸Šå‡çµæ§‹ ({trend_result})"

    # --- 2. å›èª¿çµæ§‹å®šä½èˆ‡ç¢ºèª (Stage II) ---
    bottoms = pivot_df[pivot_df['Pivot_Type'] == -1]['Pivot_Price'].dropna()
    tops = pivot_df[pivot_df['Pivot_Type'] == 1]['Pivot_Price'].dropna()
    
    if len(bottoms) < 2 or len(tops) < 1:
        return False, "çµæ§‹è½‰æŠ˜é»ä¸è¶³ï¼Œç„¡æ³•å®šä½å›èª¿å€é–“"

    T_last = tops.iloc[-1]
    B_pre_T = bottoms.iloc[-2]  

    is_correcting = (current['close'] < T_last)
    is_holding_support = (current['low'] > B_pre_T)
    
    if not (is_correcting and is_holding_support):
        if current['close'] > T_last:
            return False, "âœ… å·²ç¶“çªç ´å‰é«˜ï¼Œå›èª¿å·²çµæŸï¼Œå±¬æ–¼æ–°çš„ä¸Šæ¼²æ³¢æ®µ"
        return False, f"ğŸš¨ çµæ§‹æ€§å›èª¿å¤±æ•—ï¼šä½é»å·²è·Œç ´çµæ§‹æ”¯æ’ B_pre_T ({B_pre_T:.2f})"


    # --- 3. èµ·æ¼²ä¿¡è™Ÿ (Stage III) ---
    is_bullish_engulfing = (
        (current['close'] > current['open']) and  
        (current['close'] > prev['open']) and  
        (current['open'] < prev['close'])
    )
    is_rebound_confirmed = (
        current['close'] > current['MA20']  
        and (current['close'] > prev['high'] or is_bullish_engulfing)
    )

    if is_rebound_confirmed:
        return True, "âœ… **ã€çµæ§‹å›èª¿èµ·æ¼²ä¿¡è™Ÿã€‘**ï¼šåƒ¹æ ¼åœ¨ B_pre_T æ”¯æ’ä¸Šç¢ºèªåè½‰ï¼"
    else:
        return False, "ğŸ’¡ **æ½›åœ¨èµ·æ¼²æç¤º**ï¼šçµæ§‹å·²ç¢ºèªç‚ºå¥åº·å›èª¿å€é–“ï¼Œç­‰å¾…å¼·å‹¢ K ç·šç¢ºèªèµ·æ¼²ï¼"


# ----------------- æ•´åˆç”Ÿæˆåœ–è¡¨ (å«è¶¨å‹¢åˆ†æå’Œè¨Šè™Ÿæª¢æŸ¥) -----------------
def generate_chart(stock_id_clean, start_date=None, end_date=None, simple_mode=False, num_rows=30, frequency='D'):
    df_original = fetch_stock_data(stock_id_clean)
    if df_original.empty: return None, f"{stock_id_clean} ç„¡è³‡æ–™", "N/A", "N/A", "neutral" # ğŸŒŸ æ–°å¢ trend_class é è¨­å€¼

    df_full = df_original.copy()
    
    # === æ•¸æ“šé »ç‡è½‰æ› ===
    if frequency == 'W':
        df_full = convert_to_weekly(df_full)
    # ==================
    
    if start_date and end_date:
        df_full = df_full[
            (df_full['date'] >= pd.to_datetime(start_date)) &
            (df_full['date'] <= pd.to_datetime(end_date))
        ]

    if df_full.empty: return None, f"{stock_id_clean} åœ¨ {start_date} ~ {end_date} ç„¡è³‡æ–™", "N/A", "N/A", "neutral" # ğŸŒŸ æ–°å¢ trend_class é è¨­å€¼

    # --- 1. æŠ€è¡“æŒ‡æ¨™è¨ˆç®— --- 
    df_tech = df_full.copy()
    # TP (Typical Price) å¿…é ˆè¨ˆç®—
    df_tech['TP'] = (df_tech['high'] + df_tech['low'] + df_tech['close']) / 3
    df_tech['line'] = df_tech.apply(lambda row: row['high'] if row['close'] > row['open'] else (row['low'] if row['close'] < row['open'] else (row['open'] + row['close']) / 2), axis=1)
    for ma in [5, 10, 20, 60]: df_tech[f"MA{ma}"] = df_tech['close'].rolling(ma).mean()
    df_tech['VOL5'] = df_tech['volume'].rolling(5).mean()
    df_tech['VOL20'] = df_tech['volume'].rolling(20).mean()
    df_tech['H-L'] = df_tech['high'] - df_tech['low']
    df_tech['H-PC'] = abs(df_tech['high'] - df_tech['close'].shift(1))
    df_tech['L-PC'] = abs(df_tech['low'] - df_tech['close'].shift(1))
    df_tech['TR'] = df_tech[['H-L', 'H-PC', 'L-PC']].max(axis=1)
    df_tech['ATR14'] = df_tech['TR'].rolling(14).mean().round(3)
    df_tech['stop_loss'] = df_tech['low'] - df_tech['ATR14'].fillna(0)
    
    # --- 2. çºè«–è½‰æŠ˜é»è™•ç† ---
    df_merged = kline_merge(df_tech.copy())
    df_divergence = find_divergence(df_merged)
    # ğŸŒŸ ä¿®æ”¹ï¼šæ¥æ”¶æœ€å¾Œä¸€å€‹æœ‰æ•ˆåˆ†å‹é»çš„æ—¥æœŸå’Œé¡å‹
    df_final, last_pivot_date, last_pivot_type = filter_pivots_for_stroke(df_divergence, df_tech.copy())

    # --- 3. è¶¨å‹¢åˆ†æèˆ‡ä¿¡è™Ÿæª¢æŸ¥ ---
    df_display = df_final.tail(num_rows).copy()
    pivot_df_full = df_final[df_final['Pivot_Type'] != 0].copy()  
    
    trend_analysis = analyze_trend_by_pivots(pivot_df_full)
    is_rebound, rebound_desc = check_rebound_signal(df_final)

    # ç¢ºä¿å–å¾—æœ€çµ‚çš„è¶¨å‹¢æè¿°
    trend_desc_final = trend_analysis['Overall_Trend']
    
    # --- ğŸŒŸ é—œéµä¿®æ­£ï¼šè¨ˆç®—ç°¡åŒ–è¶¨å‹¢åˆ†é¡ (Trend Class) ğŸŒŸ ---
    trend_class = 'neutral'
    
    # çœ‹ç©ºåˆ¤æ–· (åŒ…æ‹¬ 'æ½›åœ¨è¶¨å‹¢åè½‰/æŒçºŒä¸‹é™ (ä¸‹ç©¿å‰åº•)' çš„é—œéµè©)
    if 'ä¸‹é™è¶¨å‹¢' in trend_desc_final or 'ä¸‹ç©¿å‰åº•' in trend_desc_final or 'æŒçºŒä¸‹é™' in trend_desc_final or 'æ½›åœ¨è¶¨å‹¢åè½‰' in trend_desc_final:
        trend_class = 'bearish' # ç¶ è‰²
        
    # çœ‹å¤šåˆ¤æ–·
    elif 'ä¸Šå‡è¶¨å‹¢' in trend_desc_final or 'ä¸Šç©¿å‰é«˜' in trend_desc_final or 'è¶¨å‹¢æŒçºŒ' in trend_desc_final:
        trend_class = 'bullish' # ç´…è‰²
        
    # ---------------------------------------------
    
    # ğŸŒŸ VWAPï¼šé‡æ–°è¨ˆç®—ï¼Œåƒ…é™æ–¼ df_display ç¯„åœ (num_rows ç­†)
    df_display['TPV_display'] = df_display['TP'] * df_display['volume']
    df_display['VWAP'] = df_display['TPV_display'].cumsum() / df_display['volume'].cumsum()
    
    # --- 4. ç¹ªè£½åœ–è¡¨ ---  
    min_price = df_display[['low', 'MA5', 'MA10', 'MA20', 'MA60', 'VWAP']].min().min()
    max_price = df_display[['high', 'MA5', 'MA10', 'MA20', 'MA60', 'VWAP']].max().max()
    price_range = max_price - min_price
    yaxis_min = min_price - price_range / 4
    yaxis_max = max_price + price_range / 4

    fig = make_subplots(
        rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.07,
        row_heights=[0.7, 0.15, 0.15],
        subplot_titles=(f"Kç·šåœ– ({frequency}ç·š, å«çºè«–åˆ†å‹)", "æˆäº¤é‡", "ATR")
    )

    # Kç·šåœ–èˆ‡æŒ‡æ¨™
    fig.add_trace(go.Candlestick(x=df_display['date'], open=df_display['open'], high=df_display['high'], low=df_display['low'], close=df_display['close'], increasing_line_color='red', decreasing_line_color='green', name=f'{frequency}ç·š'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['stop_loss'], mode='lines', line=dict(dash='dot'), name='æ­¢æåƒ¹'), row=1, col=1)
    ma_colors = {5: 'blue', 10: 'orange', 20: 'purple', 60: 'black'}
    for ma in [5, 10, 20, 60]: fig.add_trace(go.Scatter(x=df_display['date'], y=df_display[f"MA{ma}"], mode='lines', line=dict(color=ma_colors[ma], width=1), name=f"MA{ma}"), row=1, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VWAP'], mode='lines', line=dict(color='orange', width=2, dash='solid'), name='ä¸»åŠ›æˆæœ¬ç·š (VWAP)'), row=1, col=1)

    # æˆäº¤é‡ & ATR
    vol_color = df_display.apply(lambda row: 'red' if row['close'] > row['open'] else ('green' if row['close'] < row['open'] else 'yellow'), axis=1)
    fig.add_trace(go.Bar(x=df_display['date'], y=df_display['volume'] / 1000, name='æˆäº¤é‡', marker_color=vol_color), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VOL5'] / 1000, mode='lines', line=dict(color='blue', width=1), name='VOL5'), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['VOL20'] / 1000, mode='lines', line=dict(color='orange', width=1), name='VOL20'), row=2, col=1)
    fig.add_trace(go.Scatter(x=df_display['date'], y=df_display['ATR14'], mode='lines', line=dict(color='red', width=1), name='ATR14'), row=3, col=1)
    
    # ğŸŒŸ çºè«–åˆ†å‹æ¨™è¨˜å’ŒæŠ˜ç·š (å¯¦æ™‚å»¶ä¼¸ç­†æ®µ)
    
    # 1. éæ¿¾å·²ç¢ºèªåˆ†å‹é»
    df_pivots_display_filtered = pivot_df_full[
        (pivot_df_full['date'] >= df_display['date'].min()) &  
        (pivot_df_full['date'] <= df_display['date'].max())
    ].dropna(subset=['Pivot_Price']).copy()

    # 2. æº–å‚™å¯¦æ™‚å»¶ä¼¸é»
    extend_points = pd.DataFrame(columns=['date', 'Pivot_Price'])
    
    if last_pivot_date and not df_display.empty:
        # æ‰¾åˆ°æœ€å¾Œä¸€å€‹åˆ†å‹é»åœ¨ df_display å…§çš„ä½ç½®
        # ä½¿ç”¨ç´¢å¼•ä¾†è™•ç†æ—¥æœŸå¯èƒ½ä¸å­˜åœ¨æ–¼ df_display çš„æƒ…æ³ (å¦‚æœ num_rows å¤ªå°)
        start_index = df_display[df_display['date'] == last_pivot_date].index
        
        if not start_index.empty:
            start_index = start_index[0]
            df_extension = df_display.loc[start_index:].copy()
            
            # æ ¹æ“šæœ€å¾Œä¸€å€‹åˆ†å‹é»çš„é¡å‹æ±ºå®šå»¶ä¼¸ç·šæ˜¯é€£ High é‚„æ˜¯ Low
            current_trend_status = trend_analysis['Overall_Trend']
            
            if last_pivot_type == 1: # æœ€å¾Œæ˜¯é ‚åˆ†å‹ (å‘ä¸‹èµ°å‹¢)
                # å»¶ä¼¸ç·šé€£æ¥ Low
                df_extension['Pivot_Price_Extension'] = df_extension['low']
                
                # æª¢æŸ¥æ˜¯å¦ä¸‹ç©¿å‰åº•
                if len(df_pivots_display_filtered) >= 2:
                    B_pre = df_pivots_display_filtered.iloc[-2]['Pivot_Price']  
                    if df_extension['low'].min() < B_pre:
                        current_trend_status = "âš ï¸ **æ½›åœ¨è¶¨å‹¢åè½‰/æŒçºŒä¸‹é™ (ä¸‹ç©¿å‰åº•)**"
                
            elif last_pivot_type == -1: # æœ€å¾Œæ˜¯åº•åˆ†å‹ (å‘ä¸Šèµ°å‹¢)
                # å»¶ä¼¸ç·šé€£æ¥ High
                df_extension['Pivot_Price_Extension'] = df_extension['high']
                
                # æª¢æŸ¥æ˜¯å¦ä¸Šç©¿å‰é«˜
                if len(df_pivots_display_filtered) >= 2:
                    T_pre = df_pivots_display_filtered.iloc[-2]['Pivot_Price']
                    if df_extension['high'].max() > T_pre:
                        current_trend_status = "âœ… **è¶¨å‹¢æŒçºŒ (ä¸Šç©¿å‰é«˜)**"
            
            # ç¢ºä¿å»¶ä¼¸ç·šå¾æœ€å¾Œä¸€å€‹åˆ†å‹é»çš„åƒ¹æ ¼é–‹å§‹
            if 'Pivot_Price_Extension' in df_extension.columns:
                df_extension.loc[start_index, 'Pivot_Price_Extension'] = df_pivots_display_filtered.iloc[-1]['Pivot_Price']
                
                extend_points = df_extension[['date', 'Pivot_Price_Extension']].rename(columns={'Pivot_Price_Extension': 'Pivot_Price'})

            # å°‡å¯¦æ™‚çªç ´åˆ¤æ–·çµæœåˆä½µåˆ°ä¸»è¶¨å‹¢åˆ†æä¸­
            trend_analysis['Overall_Trend'] = current_trend_status


    # 3. åˆä½µå·²ç¢ºèªé»å’Œå»¶ä¼¸é»é€²è¡Œç¹ªåœ–
    if not df_pivots_display_filtered.empty:
        plot_points = df_pivots_display_filtered[['date', 'Pivot_Price']].copy()
        
        # é™„åŠ å»¶ä¼¸é» (ç¢ºä¿ä¸é‡è¤‡)
        if not extend_points.empty:
            start_date_filter = plot_points['date'].max()
            new_extension = extend_points[extend_points['date'] >= start_date_filter] # ä½¿ç”¨ >= ç¢ºä¿é€£ç·šé»é‡è¤‡
            plot_points = pd.concat([plot_points, new_extension], ignore_index=True).drop_duplicates(subset=['date'], keep='last')
            
        # ç¹ªè£½åˆ†å‹è¶¨å‹¢é€£ç·š (é»‘è‰²æŠ˜ç·š)
        fig.add_trace(go.Scatter(
            x=plot_points['date'],  
            y=plot_points['Pivot_Price'],  
            mode='lines',  
            line=dict(color='black', width=2, dash='solid'),  
            name='åˆ†å‹è¶¨å‹¢é€£ç·š (å¯¦æ™‚ç­†æ®µ)'
        ), row=1, col=1)

        # ç¹ªè£½åœ“åœˆæ¨™è¨˜ (åªç¹ªè£½å·²ç¢ºèªçš„åˆ†å‹é», é»‘è‰², size=8)
        df_top = df_pivots_display_filtered[df_pivots_display_filtered['Pivot_Type']==1]
        fig.add_trace(go.Scatter(
            x=df_top['date'], y=df_top['Pivot_Price'], mode='markers',  
            marker=dict(size=8, color='black', symbol='circle', line=dict(width=1, color='black')),  
            name='é ‚åˆ†å‹', hoverinfo='text',
            text=[f"é ‚åˆ†å‹: {p:.2f}" for p in df_top['Pivot_Price']], uid='top_pivot_marker',
        ), row=1, col=1)
        
        df_bottom = df_pivots_display_filtered[df_pivots_display_filtered['Pivot_Type']==-1]
        fig.add_trace(go.Scatter(
            x=df_bottom['date'], y=df_bottom['Pivot_Price'], mode='markers',  
            marker=dict(size=8, color='black', symbol='circle', line=dict(width=1, color='black')),  
            name='åº•åˆ†å‹', hoverinfo='text',
            text=[f"åº•åˆ†å‹: {p:.2f}" for p in df_bottom['Pivot_Price']], uid='bottom_pivot_marker',
        ), row=1, col=1)
        
    stock_name = df_display['stock_name'].iloc[0] if 'stock_name' in df_display.columns and not df_display.empty else stock_id_clean
    first_date = df_display['date'].iloc[0].strftime("%Y-%m-%d")
    last_date = df_display['date'].iloc[-1].strftime("%Y-%m-%d")

    fig.update_layout(
        title=dict(
            # ğŸŒŸ å°‡å¯¦æ™‚çªç ´åˆ¤æ–·çµæœé¡¯ç¤ºåœ¨æ¨™é¡Œ
            text=f"{stock_id_clean} ({stock_name}) - {frequency}ç·šè¶¨å‹¢: {trend_analysis['Overall_Trend']} ({first_date} ~ {last_date})",
            x=0.5, xanchor='center'
        ),
        xaxis_rangeslider_visible=False, hovermode='x unified', dragmode='drawline',
        newshape=dict(line_color='black', line_width=2),
        modebar_add=['drawline', 'drawopenpath', 'drawrect', 'drawcircle', 'eraseshape'],
        yaxis=dict(range=[yaxis_min, yaxis_max]),
        height=1200
    )

    html = fig.to_html(include_plotlyjs='cdn')
    
    # ğŸŒŸ ä¿®æ”¹å›å‚³å€¼ï¼Œæ–°å¢ trend_class
    return html, None, trend_analysis['Overall_Trend'], rebound_desc, trend_class

# ----------------- Flask è·¯ç”±éƒ¨åˆ† -----------------

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/query', methods=['POST'])
def query():
    stock_id = request.form['stock_id'].strip()
    simple_mode = request.form.get('simple_mode') == '1'
    num_rows = request.form.get('num_rows', type=int, default=30)
    frequency = request.form.get('frequency', 'D')
    
    # ğŸŒŸ ä¿®æ”¹æ¥æ”¶è®Šæ•¸
    chart_html, error, trend_desc, rebound_desc, trend_class = generate_chart(stock_id, simple_mode=simple_mode, num_rows=num_rows, frequency=frequency)
    
    if error: return f"<h2>{error}</h2><a href='/'>è¿”å›</a>"
    # is_favorite å‡½æ•¸å·²è¢«ç§»å‹•åˆ°å‰æ–¹ï¼Œå› æ­¤æ­¤è™•å¯ä»¥æ­£ç¢ºå‘¼å«
    fav_status = is_favorite(stock_id) 
    
    return render_template(
        'chart.html',  
        chart_html=chart_html,  
        stock_id=stock_id,  
        stock_list=stock_id,  
        current_index=0,  
        simple_mode=simple_mode,  
        num_rows=num_rows,  
        is_favorite=fav_status,
        trend_desc=trend_desc,
        rebound_desc=rebound_desc,
        # ğŸŒŸ å‚³éæ–°çš„è®Šæ•¸åˆ°å‰ç«¯
        trend_class=trend_class,
        frequency=frequency
    )

@app.route('/chart/<stock_id>/')
@app.route('/chart/<stock_id>')
def chart_from_list(stock_id):
    stock_id = stock_id.strip()
    simple_mode = request.args.get('simple_mode') == '1'
    num_rows = request.args.get('num_rows', type=int, default=30)
    stock_list = request.args.get('list', '')
    index = request.args.get('index', type=int, default=0)
    frequency = request.args.get('frequency', 'D')

    stock_ids = stock_list.split(',') if stock_list else [stock_id]
    index = max(0, min(index, len(stock_ids)-1))

    current_stock = stock_ids[index]
    # ğŸŒŸ ä¿®æ”¹æ¥æ”¶è®Šæ•¸
    chart_html, error, trend_desc, rebound_desc, trend_class = generate_chart(current_stock, simple_mode=simple_mode, num_rows=num_rows, frequency=frequency)
    
    if error: return f"<h2>{error}</h2><a href='/'>è¿”å›</a>"
    # is_favorite å‡½æ•¸å·²è¢«ç§»å‹•åˆ°å‰æ–¹ï¼Œå› æ­¤æ­¤è™•å¯ä»¥æ­£ç¢ºå‘¼å«
    fav_status = is_favorite(current_stock)

    return render_template(
        'chart.html',  
        chart_html=chart_html,  
        stock_id=current_stock,  
        stock_list=','.join(stock_ids),  
        current_index=index,  
        simple_mode=simple_mode,  
        num_rows=num_rows,  
        is_favorite=fav_status,
        trend_desc=trend_desc,
        rebound_desc=rebound_desc,
        # ğŸŒŸ å‚³éæ–°çš„è®Šæ•¸åˆ°å‰ç«¯
        trend_class=trend_class,
        frequency=frequency
    )

# ----------------- Filter åŠ Favorite è·¯ç”± -----------------
@app.route('/filter', methods=['POST'])
def filter_stocks():
    volume_min = request.form.get('volume_min', type=float, default=0)
    trend_type = request.form.get('trend_type', '')
    adr14_min = request.form.get('change_min', type=float, default=0)
    simple_mode = request.form.get('simple_mode') == '1'
    num_rows = request.form.get('num_rows', type=int, default=60)
    recent_days = request.form.get('recent_days', type=int, default=30)
    frequency = request.form.get('frequency', 'D')

    recent_date = (datetime.today() - timedelta(days=recent_days)).strftime("%Y-%m-%d")
    all_data = []
    limit = 1000
    offset = 0

    while True:
        try:
            res = requests.get(f"{SUPABASE_URL}/rest/v1/quick_view", headers=headers,
                params={
                    "latest_volume": f"gte.{int(volume_min)}",
                    "adr14": f"gte.{adr14_min}",
                    "latest_date": f"gte.{recent_date}",
                    "trend": f"eq.{trend_type}" if trend_type else None,
                    "order": "latest_date.desc", "limit": limit, "offset": offset, "select": "*"
                }, timeout=30
            )
            res.raise_for_status()
            data = res.json()
            if not data: break
            all_data.extend(data)
            if len(data) < limit: break
            offset += limit
        except Exception as e: return f"<h2>Supabase è®€å– QUICK_VIEW å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"

    if not all_data: return "<h2>æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨</h2><a href='/'>è¿”å›</a>"
    df = pd.DataFrame(all_data)
    stock_ids = [str(sid) for sid in df['stock_id']]
    count = len(df); list_param = urllib.parse.quote(','.join(stock_ids))
    
    html = (f"<h2>ç¯©é¸çµæœï¼ˆå…± {count} ç­†ï¼‰</h2>" "<table border='1' cellpadding='6' style='margin-left:0; text-align:left;'>" "<thead><tr>" "<th>è‚¡ç¥¨ä»£è™Ÿ</th><th>è‚¡ç¥¨åç¨±</th><th>æˆäº¤é‡</th>" "<th>ADR14(%)</th><th>14å¤©å¹³å‡æˆäº¤é‡</th><th>è¶¨å‹¢</th>" "</tr></thead><tbody>")
    for idx, row in df.iterrows():
        simple_param = "1" if simple_mode else "0"
        html += (f"<tr>"  
                    f"<td><a href='/chart/{row['stock_id']}?simple_mode={simple_param}&num_rows={num_rows}&list={list_param}&index={idx}&frequency={frequency}'>{row['stock_id']}</a></td>"  
                    f"<td>{row['stock_name']}</td>"  
                    f"<td>{int(row['latest_volume'])}</td>"  
                    f"<td>{row['adr14']:.2f}</td>"  
                    f"<td>{int(row['avg_volume_14'])}</td>"  
                    f"<td>{row['trend']}</td>"  
                    f"</tr>")
    html += "</tbody></table><br><a href='/'>è¿”å›</a>"
    return html

@app.route('/favorites', methods=['POST'])
def favorites_page():
    simple_mode = request.form.get('simple_mode') == '1'
    num_rows = request.form.get('num_rows', type=int, default=30)
    frequency = request.form.get('frequency', 'D')
    
    try:
        res = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers); res.raise_for_status(); fav_data = res.json()
    except Exception as e: return f"<h2>è®€å–æœ€æ„›è‚¡ç¥¨å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"
    if not fav_data: return "<h2>å°šç„¡æœ€æ„›è‚¡ç¥¨</h2><a href='/'>è¿”å›</a>"
    stock_ids = [item['stock_id'] for item in fav_data]
    try:
        res_qv = requests.get(f"{SUPABASE_URL}/rest/v1/quick_view", headers=headers, params={"stock_id": f"in.({','.join(stock_ids)})", "order": "latest_date.desc", "select": "*"})
        res_qv.raise_for_status(); qv_data = res_qv.json()
    except Exception as e: return f"<h2>è®€å–æœ€æ„›è‚¡ç¥¨å¿«ç…§è³‡æ–™å¤±æ•—: {e}</h2><a href='/'>è¿”å›</a>"

    df_qv = pd.DataFrame(qv_data); count = len(df_qv); list_param = urllib.parse.quote(','.join(stock_ids))
    
    html = (f"<h2>æˆ‘çš„æœ€æ„›ï¼ˆå…± {count} ç­†ï¼‰</h2>" "<form method='post' action='/favorites_clear' " "onsubmit=\"return confirm('ç¢ºå®šè¦åˆªé™¤æ‰€æœ‰æœ€æ„›å—ï¼Ÿ');\">" "<button type='submit' style='margin-bottom:10px;'>åˆªé™¤å…¨éƒ¨æœ€æ„›</button>" "</form>" "<table border='1' cellpadding='6' style='margin-left:0; text-align:left;'>" "<thead><tr>" "<th>è‚¡ç¥¨ä»£è™Ÿ</th><th>è‚¡ç¥¨åç¨±</th><th>æˆäº¤é‡</th>" "<th>ADR14(%)</th><th>14å¤©å¹³å‡æˆäº¤é‡</th><th>è¶¨å‹¢</th>" "</tr></thead><tbody>")
    for idx, row in df_qv.iterrows():
        simple_param = "1" if simple_mode else "0"
        html += (f"<tr>"  
                    f"<td><a href='/chart/{row['stock_id']}?simple_mode={simple_param}&num_rows={num_rows}&list={list_param}&index={idx}&frequency={frequency}'>{row['stock_id']}</a></td>"  
                    f"<td>{row['stock_name']}</td>"  
                    f"<td>{int(row['latest_volume'])}</td>"  
                    f"<td>{row['adr14']:.2f}</td>"  
                    f"<td>{int(row['avg_volume_14'])}</td>"  
                    f"<td>{row['trend']}</td>"  
                    f"</tr>")
    html += "</tbody></table><br><a href='/'>è¿”å›</a>"
    return html

@app.route('/favorite', methods=['POST'])
def favorite_toggle():
    stock_id = request.form.get('stock_id', '').strip(); stock_name = request.form.get('stock_name', '').strip()
    if not stock_id: return jsonify({"message": "è‚¡ç¥¨ä»£è™Ÿä¸å¯ç‚ºç©º"}), 400
    try:
        res_check = requests.get(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params={"stock_id": f"eq.{stock_id}"}); res_check.raise_for_status(); exists = len(res_check.json()) > 0
    except Exception as e: return jsonify({"message": f"æª¢æŸ¥æœ€æ„›å¤±æ•—: {e}"}), 500

    try:
        if exists:
            res = requests.delete(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params={"stock_id": f"eq.{stock_id}"}); res.raise_for_status()
            return jsonify({"message": f"{stock_name} å·²å¾æœ€æ„›ç§»é™¤", "favorite": False})
        else:
            payload = {"stock_id": stock_id, "stock_name": stock_name}
            res = requests.post(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers={**headers, "Content-Type": "application/json"}, json=payload); res.raise_for_status()
            return jsonify({"message": f"{stock_name} å·²åŠ å…¥æœ€æ„›", "favorite": True})
    except Exception as e: return jsonify({"message": f"æ“ä½œæœ€æ„›å¤±æ•—: {e}"}), 500

@app.route('/favorites_clear', methods=['POST'])
def favorites_clear():
    try:
        res = requests.delete(f"{SUPABASE_URL}/rest/v1/{FAVORITE_TABLE}", headers=headers, params={"stock_id": "not.is.null"})  
        res.raise_for_status(); return "<script>alert('å·²åˆªé™¤æ‰€æœ‰æœ€æ„›è‚¡ç¥¨'); window.location.href='/'</script>"
    except Exception as e: return f"<h2>åˆªé™¤æœ€æ„›å¤±æ•—: {e}</h2><a href='/'>è¿”å›é¦–é </a>"

# ----------------- é‹è¡Œç¨‹å¼ -----------------
if __name__ == '__main__':
    import os
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)